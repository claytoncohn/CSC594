{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_pretraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ilkS7uBtjl"
      },
      "source": [
        "Clayton Cohn <br>\n",
        "CSC 594: Advanced Topics in Deep Learning <br>\n",
        "27 Oct 2020 <br>\n",
        "Assignment 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJQja0ZOB_uS"
      },
      "source": [
        "##<center>run_pretraining.py (ANNOTATED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYGkwW9wCNZq"
      },
      "source": [
        "This is an annotation of the ```run_pretraining.py``` file from Google BERT's GitHub repository: https://github.com/google-research/bert. It is used with the authors' permission unter the Apache 2.0 license.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoOJJDQ0C99w"
      },
      "source": [
        "```run_pretraining.py``` is intended for use to further pretrain BERT with custom corpora (or train/retrain it from scratch). This code only processes data that was first fed through ```create_pretraining_data.py```, which takes a raw text file and creates the Masked Sentene Model (MLM) and Next Sentence Prediction (NSP) instances from which to conduct pretraining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhQdWzfrEL9O"
      },
      "source": [
        "The code first sets up its imports and flags. ```tf.flags``` are used to set default values for command line arguments. When running the code, I did not change any of the parametersâ€”they are set to the paramters that BERT was originally trained on. However, one has the option to change the learning rate, batch size, etc. The masking rate hyperparameter is located in ```create_pretraining_data.py```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yVpllF2C0gD"
      },
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2018 The Google AI Language Team Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"Run masked LM/next sentence masked_lm pre-training for BERT.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import modeling\n",
        "import optimization\n",
        "import tensorflow as tf\n",
        "\n",
        "flags = tf.flags\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "## Required parameters\n",
        "flags.DEFINE_string(\n",
        "    \"bert_config_file\", None,\n",
        "    \"The config json file corresponding to the pre-trained BERT model. \"\n",
        "    \"This specifies the model architecture.\")\n",
        "\n",
        "flags.DEFINE_string(\n",
        "    \"input_file\", None,\n",
        "    \"Input TF example files (can be a glob or comma separated).\")\n",
        "\n",
        "flags.DEFINE_string(\n",
        "    \"output_dir\", None,\n",
        "    \"The output directory where the model checkpoints will be written.\")\n",
        "\n",
        "## Other parameters\n",
        "flags.DEFINE_string(\n",
        "    \"init_checkpoint\", None,\n",
        "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"max_seq_length\", 128,\n",
        "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
        "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
        "    \"than this will be padded. Must match data generation.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"max_predictions_per_seq\", 20,\n",
        "    \"Maximum number of masked LM predictions per sequence. \"\n",
        "    \"Must match data generation.\")\n",
        "\n",
        "flags.DEFINE_bool(\"do_train\", False, \"Whether to run training.\")\n",
        "\n",
        "flags.DEFINE_bool(\"do_eval\", False, \"Whether to run eval on the dev set.\")\n",
        "\n",
        "flags.DEFINE_integer(\"train_batch_size\", 32, \"Total batch size for training.\")\n",
        "\n",
        "flags.DEFINE_integer(\"eval_batch_size\", 8, \"Total batch size for eval.\")\n",
        "\n",
        "flags.DEFINE_float(\"learning_rate\", 5e-5, \"The initial learning rate for Adam.\")\n",
        "\n",
        "flags.DEFINE_integer(\"num_train_steps\", 100000, \"Number of training steps.\")\n",
        "\n",
        "flags.DEFINE_integer(\"num_warmup_steps\", 10000, \"Number of warmup steps.\")\n",
        "\n",
        "flags.DEFINE_integer(\"save_checkpoints_steps\", 1000,\n",
        "                     \"How often to save the model checkpoint.\")\n",
        "\n",
        "flags.DEFINE_integer(\"iterations_per_loop\", 1000,\n",
        "                     \"How many steps to make in each estimator call.\")\n",
        "\n",
        "flags.DEFINE_integer(\"max_eval_steps\", 100, \"Maximum number of eval steps.\")\n",
        "\n",
        "flags.DEFINE_bool(\"use_tpu\", False, \"Whether to use TPU or GPU/CPU.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\n",
        "    \"tpu_name\", None,\n",
        "    \"The Cloud TPU to use for training. This should be either the name \"\n",
        "    \"used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 \"\n",
        "    \"url.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\n",
        "    \"tpu_zone\", None,\n",
        "    \"[Optional] GCE zone where the Cloud TPU is located in. If not \"\n",
        "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
        "    \"metadata.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\n",
        "    \"gcp_project\", None,\n",
        "    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n",
        "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
        "    \"metadata.\")\n",
        "\n",
        "tf.flags.DEFINE_string(\"master\", None, \"[Optional] TensorFlow master URL.\")\n",
        "\n",
        "flags.DEFINE_integer(\n",
        "    \"num_tpu_cores\", 8,\n",
        "    \"Only used if `use_tpu` is True. Total number of TPU cores to use.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJGIQqBVFyWl"
      },
      "source": [
        "The code then defines its ```model_fn_builder``` function, which returns a closure for the TPUEstimator. TPUEstimator is native to TensorFlow and handles many of the behind-the-scenes details when training on TPUs.\n",
        "\n",
        "According to TensorFlow.org's documentation:\n",
        "\n",
        "<i>\"TPUEstimator handles many of the details of running on TPU devices, such as replicating inputs and models for each core, and returning to host periodically to run hooks. TPUEstimator transforms a global batch size in params to a per-shard batch size when calling the input_fn and model_fn.\"</i>\n",
        "\n",
        "This function is called once at the beginning of training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs0_21I-HGZa"
      },
      "source": [
        "def model_fn_builder(bert_config, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mjbGzhHJtp"
      },
      "source": [
        "```model_fn``` is the closure that is returned to ```model_fn_builder```. Again, this deals with TPU processing behind the scenes. It is also where the model gets built."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2iOWhB9Hq6p"
      },
      "source": [
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkHKoMNJH1xh"
      },
      "source": [
        "Within the ```model_fn``` function, the function uses its ```features``` argument to define the BERT model and initialize the loss from both the MLP and NSP. This closure passes all pertinent information once training begins to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jReAQFmiI1R8"
      },
      "source": [
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    masked_lm_positions = features[\"masked_lm_positions\"]\n",
        "    masked_lm_ids = features[\"masked_lm_ids\"]\n",
        "    masked_lm_weights = features[\"masked_lm_weights\"]\n",
        "    next_sentence_labels = features[\"next_sentence_labels\"]\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    model = modeling.BertModel(\n",
        "        config=bert_config,\n",
        "        is_training=is_training,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        token_type_ids=segment_ids,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "    (masked_lm_loss,\n",
        "     masked_lm_example_loss, masked_lm_log_probs) = get_masked_lm_output(\n",
        "         bert_config, model.get_sequence_output(), model.get_embedding_table(),\n",
        "         masked_lm_positions, masked_lm_ids, masked_lm_weights)\n",
        "\n",
        "    (next_sentence_loss, next_sentence_example_loss,\n",
        "     next_sentence_log_probs) = get_next_sentence_output(\n",
        "         bert_config, model.get_pooled_output(), next_sentence_labels)\n",
        "\n",
        "    total_loss = masked_lm_loss + next_sentence_loss\n",
        "\n",
        "    tvars = tf.trainable_variables()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJhW65UFKFWv"
      },
      "source": [
        "The ```model_fn``` also checks to see if the user is restoring training from a checkpoint. The user can start from scratch with no training weights, or (as is more common) he or she can start with BERT's weights and fine-tune them for more esoteric subject matter.<br><br>\n",
        "Additionally, these checkpoints come in handy, as Colab has a habit of bootintg people during long rounds of training. When this happens, it is nice to have these checkpoints, as they are automatically generated and retrieved (as long as you define the file)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovF2FYfsLOHG"
      },
      "source": [
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names\n",
        "      ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    tf.logging.info(\"**** Trainable Variables ****\")\n",
        "    for var in tvars:\n",
        "      init_string = \"\"\n",
        "      if var.name in initialized_variable_names:\n",
        "        init_string = \", *INIT_FROM_CKPT*\"\n",
        "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvgpHIkTLibG"
      },
      "source": [
        "Like most training in machine learning, the user has the option to evaluate performance on a dev set. The user can specify whether they want to do training, evaluation, or both. This is established in the ```tf.flags``` at the top of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxbUM8stMLlZ"
      },
      "source": [
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op,\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjerC6KKMaJd"
      },
      "source": [
        "During evaluation, the model itself is not trained (i.e. BERT's weights are not updated). The below ```metric_fn``` function is used to generate the losses and accuracies for both the MLM and NSP tasks during evaluation. These values are then returned via the ```metric_fn``` closure. If some other mode is identififed other than TRAIN or EVAL, an exception is raised."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86SWV-lyMZpL"
      },
      "source": [
        "      def metric_fn(masked_lm_example_loss, masked_lm_log_probs, masked_lm_ids,\n",
        "                    masked_lm_weights, next_sentence_example_loss,\n",
        "                    next_sentence_log_probs, next_sentence_labels):\n",
        "        \"\"\"Computes the loss and accuracy of the model.\"\"\"\n",
        "        masked_lm_log_probs = tf.reshape(masked_lm_log_probs,\n",
        "                                         [-1, masked_lm_log_probs.shape[-1]])\n",
        "        masked_lm_predictions = tf.argmax(\n",
        "            masked_lm_log_probs, axis=-1, output_type=tf.int32)\n",
        "        masked_lm_example_loss = tf.reshape(masked_lm_example_loss, [-1])\n",
        "        masked_lm_ids = tf.reshape(masked_lm_ids, [-1])\n",
        "        masked_lm_weights = tf.reshape(masked_lm_weights, [-1])\n",
        "        masked_lm_accuracy = tf.metrics.accuracy(\n",
        "            labels=masked_lm_ids,\n",
        "            predictions=masked_lm_predictions,\n",
        "            weights=masked_lm_weights)\n",
        "        masked_lm_mean_loss = tf.metrics.mean(\n",
        "            values=masked_lm_example_loss, weights=masked_lm_weights)\n",
        "\n",
        "        next_sentence_log_probs = tf.reshape(\n",
        "            next_sentence_log_probs, [-1, next_sentence_log_probs.shape[-1]])\n",
        "        next_sentence_predictions = tf.argmax(\n",
        "            next_sentence_log_probs, axis=-1, output_type=tf.int32)\n",
        "        next_sentence_labels = tf.reshape(next_sentence_labels, [-1])\n",
        "        next_sentence_accuracy = tf.metrics.accuracy(\n",
        "            labels=next_sentence_labels, predictions=next_sentence_predictions)\n",
        "        next_sentence_mean_loss = tf.metrics.mean(\n",
        "            values=next_sentence_example_loss)\n",
        "\n",
        "        return {\n",
        "            \"masked_lm_accuracy\": masked_lm_accuracy,\n",
        "            \"masked_lm_loss\": masked_lm_mean_loss,\n",
        "            \"next_sentence_accuracy\": next_sentence_accuracy,\n",
        "            \"next_sentence_loss\": next_sentence_mean_loss,\n",
        "        }\n",
        "\n",
        "      eval_metrics = (metric_fn, [\n",
        "          masked_lm_example_loss, masked_lm_log_probs, masked_lm_ids,\n",
        "          masked_lm_weights, next_sentence_example_loss,\n",
        "          next_sentence_log_probs, next_sentence_labels\n",
        "      ])\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metrics=eval_metrics,\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    else:\n",
        "      raise ValueError(\"Only TRAIN and EVAL modes are supported: %s\" % (mode))\n",
        "\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3OMPbdCOoND"
      },
      "source": [
        "The next function defined is ```get_masked_lm_output```. As the name suggests, this function returns the loss from the MLM. As inputs, it takes a BERT configuration, an input tensor, output weights, positional encodings, labels, and label weights. The calculations are standard for deep learning, i.e. linear algebra to calculate weights, biases, and activations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO03luuwOhvt"
      },
      "source": [
        "def get_masked_lm_output(bert_config, input_tensor, output_weights, positions,\n",
        "                         label_ids, label_weights):\n",
        "  \"\"\"Get loss and log probs for the masked LM.\"\"\"\n",
        "  input_tensor = gather_indexes(input_tensor, positions)\n",
        "\n",
        "  with tf.variable_scope(\"cls/predictions\"):\n",
        "    # We apply one more non-linear transformation before the output layer.\n",
        "    # This matrix is not used after pre-training.\n",
        "    with tf.variable_scope(\"transform\"):\n",
        "      input_tensor = tf.layers.dense(\n",
        "          input_tensor,\n",
        "          units=bert_config.hidden_size,\n",
        "          activation=modeling.get_activation(bert_config.hidden_act),\n",
        "          kernel_initializer=modeling.create_initializer(\n",
        "              bert_config.initializer_range))\n",
        "      input_tensor = modeling.layer_norm(input_tensor)\n",
        "\n",
        "    # The output weights are the same as the input embeddings, but there is\n",
        "    # an output-only bias for each token.\n",
        "    output_bias = tf.get_variable(\n",
        "        \"output_bias\",\n",
        "        shape=[bert_config.vocab_size],\n",
        "        initializer=tf.zeros_initializer())\n",
        "    logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    label_ids = tf.reshape(label_ids, [-1])\n",
        "    label_weights = tf.reshape(label_weights, [-1])\n",
        "\n",
        "    one_hot_labels = tf.one_hot(\n",
        "        label_ids, depth=bert_config.vocab_size, dtype=tf.float32)\n",
        "\n",
        "    # The `positions` tensor might be zero-padded (if the sequence is too\n",
        "    # short to have the maximum number of predictions). The `label_weights`\n",
        "    # tensor has a value of 1.0 for every real prediction and 0.0 for the\n",
        "    # padding predictions.\n",
        "    per_example_loss = -tf.reduce_sum(log_probs * one_hot_labels, axis=[-1])\n",
        "    numerator = tf.reduce_sum(label_weights * per_example_loss)\n",
        "    denominator = tf.reduce_sum(label_weights) + 1e-5\n",
        "    loss = numerator / denominator\n",
        "\n",
        "  return (loss, per_example_loss, log_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2WzqRlOc90Y"
      },
      "source": [
        "The next function defined is ```get_next_sentence_output```. As the name suggests, this function returns the loss from the NSP. As inputs, it takes a BERT configuration, an input tensor, and labels. It also uses standard deep learning matrix operations for computation.\n",
        "\n",
        "NSP tends to converge much faster due to it being a binary classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKwNbYHldjfp"
      },
      "source": [
        "def get_next_sentence_output(bert_config, input_tensor, labels):\n",
        "  \"\"\"Get loss and log probs for the next sentence prediction.\"\"\"\n",
        "\n",
        "  # Simple binary classification. Note that 0 is \"next sentence\" and 1 is\n",
        "  # \"random sentence\". This weight matrix is not used after pre-training.\n",
        "  with tf.variable_scope(\"cls/seq_relationship\"):\n",
        "    output_weights = tf.get_variable(\n",
        "        \"output_weights\",\n",
        "        shape=[2, bert_config.hidden_size],\n",
        "        initializer=modeling.create_initializer(bert_config.initializer_range))\n",
        "    output_bias = tf.get_variable(\n",
        "        \"output_bias\", shape=[2], initializer=tf.zeros_initializer())\n",
        "\n",
        "    logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "    labels = tf.reshape(labels, [-1])\n",
        "    one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, per_example_loss, log_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xseP4eNceJez"
      },
      "source": [
        "The ```gather_indexes``` method is a helper function that takes a tensor and an array of indexes as inputs. It is used to isolate vectors at specific positions in the minibacth during training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgoAbEq7eNxg"
      },
      "source": [
        "def gather_indexes(sequence_tensor, positions):\n",
        "  \"\"\"Gathers the vectors at the specific positions over a minibatch.\"\"\"\n",
        "  sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n",
        "  batch_size = sequence_shape[0]\n",
        "  seq_length = sequence_shape[1]\n",
        "  width = sequence_shape[2]\n",
        "\n",
        "  flat_offsets = tf.reshape(\n",
        "      tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n",
        "  flat_positions = tf.reshape(positions + flat_offsets, [-1])\n",
        "  flat_sequence_tensor = tf.reshape(sequence_tensor,\n",
        "                                    [batch_size * seq_length, width])\n",
        "  output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n",
        "  return output_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpL6I-oCeq9p"
      },
      "source": [
        "The ```input_fn_builder``` function creates an ```input_fn``` closure that is passed to the TPUEstimator to handle. This is similar to the ```model_fn_builder``` function toward the beginning of the file, except that this function is called before each batch is processed during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV3Jr8yqerJL"
      },
      "source": [
        "def input_fn_builder(input_files,\n",
        "                     max_seq_length,\n",
        "                     max_predictions_per_seq,\n",
        "                     is_training,\n",
        "                     num_cpu_threads=4):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StnUFPKRf565"
      },
      "source": [
        "Just like the ```model_fn``` closure above, there is a similar ```input_fn``` closure here. It is used as a vessel to communicate ids, masks, labels, positions, and weights via a features dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfiq5m5If6C3"
      },
      "source": [
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    name_to_features = {\n",
        "        \"input_ids\":\n",
        "            tf.FixedLenFeature([max_seq_length], tf.int64),\n",
        "        \"input_mask\":\n",
        "            tf.FixedLenFeature([max_seq_length], tf.int64),\n",
        "        \"segment_ids\":\n",
        "            tf.FixedLenFeature([max_seq_length], tf.int64),\n",
        "        \"masked_lm_positions\":\n",
        "            tf.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
        "        \"masked_lm_ids\":\n",
        "            tf.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
        "        \"masked_lm_weights\":\n",
        "            tf.FixedLenFeature([max_predictions_per_seq], tf.float32),\n",
        "        \"next_sentence_labels\":\n",
        "            tf.FixedLenFeature([1], tf.int64),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkymgLN-gji8"
      },
      "source": [
        "This next section makes sure that training runs in parallel and that the training data is shuffled. There is also an interesting \"sloppy\" mode that adds randomness to training by not perfectly interleaving while shuffling (similar to a deck of cards). If the model is evaluating, as opposed to training, then the tensors are not shuffled and parallelization is not a priority. \n",
        "\n",
        "The closure returns the (tensorized, shuffled, parallelized) dataset, and the function returns the closure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "athIGsFHgjqp"
      },
      "source": [
        "    # For training, we want a lot of parallel reading and shuffling.\n",
        "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
        "    if is_training:\n",
        "      d = tf.data.Dataset.from_tensor_slices(tf.constant(input_files))\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=len(input_files))\n",
        "\n",
        "      # `cycle_length` is the number of parallel files that get read.\n",
        "      cycle_length = min(num_cpu_threads, len(input_files))\n",
        "\n",
        "      # `sloppy` mode means that the interleaving is not exact. This adds\n",
        "      # even more randomness to the training pipeline.\n",
        "      d = d.apply(\n",
        "          tf.contrib.data.parallel_interleave(\n",
        "              tf.data.TFRecordDataset,\n",
        "              sloppy=is_training,\n",
        "              cycle_length=cycle_length))\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "    else:\n",
        "      d = tf.data.TFRecordDataset(input_files)\n",
        "      # Since we evaluate for a fixed number of steps we don't want to encounter\n",
        "      # out-of-range exceptions.\n",
        "      d = d.repeat()\n",
        "\n",
        "    # We must `drop_remainder` on training because the TPU requires fixed\n",
        "    # size dimensions. For eval, we assume we are evaluating on the CPU or GPU\n",
        "    # and we *don't* want to drop the remainder, otherwise we wont cover\n",
        "    # every sample.\n",
        "    d = d.apply(\n",
        "        tf.contrib.data.map_and_batch(\n",
        "            lambda record: _decode_record(record, name_to_features),\n",
        "            batch_size=batch_size,\n",
        "            num_parallel_batches=num_cpu_threads,\n",
        "            drop_remainder=True))\n",
        "    return d\n",
        "\n",
        "  return input_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhBko8cHiNKN"
      },
      "source": [
        "The ```_decode_record``` function is a helper function that converts TFRecord binary data to tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-SJFMdViNUm"
      },
      "source": [
        "def _decode_record(record, name_to_features):\n",
        "  \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
        "  example = tf.parse_single_example(record, name_to_features)\n",
        "\n",
        "  # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
        "  # So cast all int64 to int32.\n",
        "  for name in list(example.keys()):\n",
        "    t = example[name]\n",
        "    if t.dtype == tf.int64:\n",
        "      t = tf.to_int32(t)\n",
        "    example[name] = t\n",
        "\n",
        "  return example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRg3dWf-lBz_"
      },
      "source": [
        "The next function is the file's ```main``` function. The first few lines handle housekeeping tasks such as logging, ensuring model has selected training or eval (or both), and setting up BERT configuration file defined via flag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdUIQOg5lCDd"
      },
      "source": [
        "def main(_):\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "  if not FLAGS.do_train and not FLAGS.do_eval:\n",
        "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
        "\n",
        "  bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
        "\n",
        "  tf.gfile.MakeDirs(FLAGS.output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exsqM5qKljuP"
      },
      "source": [
        "Input files are then read and configurations are set based on flags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAlz0ecPlj6F"
      },
      "source": [
        "  input_files = []\n",
        "  for input_pattern in FLAGS.input_file.split(\",\"):\n",
        "    input_files.extend(tf.gfile.Glob(input_pattern))\n",
        "\n",
        "  tf.logging.info(\"*** Input Files ***\")\n",
        "  for input_file in input_files:\n",
        "    tf.logging.info(\"  %s\" % input_file)\n",
        "\n",
        "  tpu_cluster_resolver = None\n",
        "  if FLAGS.use_tpu and FLAGS.tpu_name:\n",
        "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "        FLAGS.tpu_name, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project)\n",
        "\n",
        "  is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "  run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      master=FLAGS.master,\n",
        "      model_dir=FLAGS.output_dir,\n",
        "      save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          iterations_per_loop=FLAGS.iterations_per_loop,\n",
        "          num_shards=FLAGS.num_tpu_cores,\n",
        "          per_host_input_for_training=is_per_host))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXmeQW2mo_Lg"
      },
      "source": [
        "The ```model_fn_builder``` method is called to build the model and return the ```model_fn``` closure that will transport all of the data relating to labels, loss, masks, etc (for both MLM and NSP tasks). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsC_uI2Vo-3h"
      },
      "source": [
        "      model_fn = model_fn_builder(\n",
        "      bert_config=bert_config,\n",
        "      init_checkpoint=FLAGS.init_checkpoint,\n",
        "      learning_rate=FLAGS.learning_rate,\n",
        "      num_train_steps=FLAGS.num_train_steps,\n",
        "      num_warmup_steps=FLAGS.num_warmup_steps,\n",
        "      use_tpu=FLAGS.use_tpu,\n",
        "      use_one_hot_embeddings=FLAGS.use_tpu)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHzhzwzYp_vh"
      },
      "source": [
        "Estimator is then set up for TPU training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNmyhZOep_59"
      },
      "source": [
        "  # If TPU is not available, this will fall back to normal Estimator on CPU\n",
        "  # or GPU.\n",
        "  estimator = tf.contrib.tpu.TPUEstimator(\n",
        "      use_tpu=FLAGS.use_tpu,\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      train_batch_size=FLAGS.train_batch_size,\n",
        "      eval_batch_size=FLAGS.eval_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy88b5aVrEkj"
      },
      "source": [
        "Flags are then read to either train or evaluate. Obviously, if both are set, training occurs first. During training, the function ```input_function_builder``` is called to return the ```input_fn``` closure for each batch. The input parameters are defined in the flags at the beginning of the document. If it is time to evaluate, the same function is invoked but this time the ```is_training``` argument is set to False, as we are only concerned with evaluating the results from each batch and not with training.\n",
        "\n",
        "During training and evaluation, the batch size is logged each iteration. After evaluation is complete, an ```eval_results.txt``` file is created and saved to store the results from evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdjPVncjrELH"
      },
      "source": [
        "  if FLAGS.do_train:\n",
        "    tf.logging.info(\"***** Running training *****\")\n",
        "    tf.logging.info(\"  Batch size = %d\", FLAGS.train_batch_size)\n",
        "    train_input_fn = input_fn_builder(\n",
        "        input_files=input_files,\n",
        "        max_seq_length=FLAGS.max_seq_length,\n",
        "        max_predictions_per_seq=FLAGS.max_predictions_per_seq,\n",
        "        is_training=True)\n",
        "    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.num_train_steps)\n",
        "\n",
        "  if FLAGS.do_eval:\n",
        "    tf.logging.info(\"***** Running evaluation *****\")\n",
        "    tf.logging.info(\"  Batch size = %d\", FLAGS.eval_batch_size)\n",
        "\n",
        "    eval_input_fn = input_fn_builder(\n",
        "        input_files=input_files,\n",
        "        max_seq_length=FLAGS.max_seq_length,\n",
        "        max_predictions_per_seq=FLAGS.max_predictions_per_seq,\n",
        "        is_training=False)\n",
        "\n",
        "    result = estimator.evaluate(\n",
        "        input_fn=eval_input_fn, steps=FLAGS.max_eval_steps)\n",
        "\n",
        "    output_eval_file = os.path.join(FLAGS.output_dir, \"eval_results.txt\")\n",
        "    with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "      tf.logging.info(\"***** Eval results *****\")\n",
        "      for key in sorted(result.keys()):\n",
        "        tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
        "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzvyvtn6shKc"
      },
      "source": [
        "This part of the code is a simple check made when the ```main``` method is called. It makes sure that three things are specified:\n",
        "\n",
        "1.   Input file containing text to train on\n",
        "2.   JSON configuration identifying architecture of BERT model\n",
        "3.   Output directroy for checkpoints and final evaluation \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LtXIpgHsgr0"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  flags.mark_flag_as_required(\"input_file\")\n",
        "  flags.mark_flag_as_required(\"bert_config_file\")\n",
        "  flags.mark_flag_as_required(\"output_dir\")\n",
        "  tf.app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}