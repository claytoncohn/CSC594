{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERTPretraining",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mh-e8r3klL2",
        "outputId": "e3028edf-0a8a-499d-af4e-3dd956ff4452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "'''\n",
        "This notebook is designed to implement further pretraining on BERT before the fine-tuning process.\n",
        "It is based on the code provided in the BERT GitHub repo by the architects: \n",
        "https://github.com/google-research/bert/#pre-training-with-bert\n",
        "'''"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nThis notebook is designed to implement further pretraining on BERT before the fine-tuning process.\\nIt is based on the code provided in the BERT GitHub repo by the architects: \\nhttps://github.com/google-research/bert/#pre-training-with-bert\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bBGoG1XkXRy"
      },
      "source": [
        "# Manual Parameters - these are not automatically generated and need to be set each runtime\n",
        "\n",
        "BERT_MODEL  = \"bert-base-uncased\"\n",
        "PRETRAINING_TYPE = \"both\" \n",
        "MAX_SEQ_LEN = int(128)\n",
        "MASKED_LM_PROB = 0.15\n",
        "SEED = 12345\n",
        "MAX_PRED_PER_SEQ = 20\n",
        "BATCH_SIZE = 32\n",
        "TRAIN_STEPS = 1234\n",
        "WARMUP_STEPS = 10\n",
        "LEARNING_RATE = 2e-5\n",
        "DUPE_FACTOR = 5\n",
        "NOTES = \"Stepping up to 100000 - LAST ITERATION\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve42V6BgGMY7",
        "outputId": "6db3160d-f840-4869-8719-8317c43237a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "328sVYlyGkvy",
        "outputId": "e5f433c9-d7df-429d-cb05-6a7c7054026f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR49KskKeOgu"
      },
      "source": [
        "RUN_PATH = 'drive/\"My Drive\"/'\n",
        "BERT_PATH = 'colab/bert/bert_base_uncased/vocab.txt'\n",
        "CORAL_PATH = 'colab/data/coral_bleaching_sentences.txt'\n",
        "TF_RECORD_PATH = 'colab/bert/bert_pretraining/coral_bleaching_pretraining.tfrecord'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XvxCluCH_Rm",
        "outputId": "93d82f2a-a784-431b-bbfa-3d1a334782d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd $RUN_PATH\n",
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            " \u001b[0m\u001b[01;34mcolab\u001b[0m/  \u001b[01;34m'Colab Notebooks'\u001b[0m/   \u001b[01;34mCSC594\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMJRIHA0HmiV",
        "outputId": "85a8166e-17ed-4acd-c1b6-0720142b5b02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python colab/bert/create_pretraining_data.py \\\n",
        "  --input_file=$CORAL_PATH \\\n",
        "  --output_file=$TF_RECORD_PATH \\\n",
        "  --vocab_file=$BERT_PATH \\\n",
        "  --do_lower_case=True \\\n",
        "  --max_seq_length=$MAX_SEQ_LEN \\\n",
        "  --max_predictions_per_seq=$MAX_PRED_PER_SEQ \\\n",
        "  --masked_lm_prob=$MASKED_LM_PROB \\\n",
        "  --random_seed=$SEED \\\n",
        "  --dupe_factor=$DUPE_FACTOR"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From colab/bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W1030 13:39:32.145976 140652228425600 module_wrapper.py:139] From colab/bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1030 13:39:32.146166 140652228425600 module_wrapper.py:139] From colab/bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/colab/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1030 13:39:32.146296 140652228425600 module_wrapper.py:139] From /content/drive/My Drive/colab/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W1030 13:39:32.968843 140652228425600 module_wrapper.py:139] From colab/bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1030 13:39:33.303391 140652228425600 module_wrapper.py:139] From colab/bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:*** Reading from input files ***\n",
            "I1030 13:39:33.303636 140652228425600 create_pretraining_data.py:446] *** Reading from input files ***\n",
            "INFO:tensorflow:  colab/data/coral_bleaching_sentences.txt\n",
            "I1030 13:39:33.303741 140652228425600 create_pretraining_data.py:448]   colab/data/coral_bleaching_sentences.txt\n",
            "INFO:tensorflow:*** Writing to output files ***\n",
            "I1030 13:39:39.757124 140652228425600 create_pretraining_data.py:457] *** Writing to output files ***\n",
            "INFO:tensorflow:  colab/bert/bert_pretraining/coral_bleaching_pretraining.tfrecord\n",
            "I1030 13:39:39.757338 140652228425600 create_pretraining_data.py:459]   colab/bert/bert_pretraining/coral_bleaching_pretraining.tfrecord\n",
            "WARNING:tensorflow:From colab/bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1030 13:39:39.757536 140652228425600 module_wrapper.py:139] From colab/bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.320912 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] photos ##yn ##thesis enslaved sensitive [MASK] different water changes . this can also [MASK] threatened by extreme storms . coral ##s are sensitive [MASK] how salty the water is . coral and zoo [MASK] ##nt ##hell ##ae algae both benefit from each other . [MASK] environmental [MASK] ##ors can threaten this bond . environmental stress ##ors can badly affect [MASK] \" balanced philipp \" between coral and zoo [MASK] ##nt ##hell ##ae . there was [MASK] massive coral b ##lea ##ching event in 1998 , it resulted in the [MASK] of 16 % of the world ' s [MASK] reefs . [SEP] these are all different reasons why the rate [MASK] coral b ##lea ##ching goes up [MASK] [SEP]\n",
            "I1030 13:39:40.321165 140652228425600 create_pretraining_data.py:151] tokens: [CLS] photos ##yn ##thesis enslaved sensitive [MASK] different water changes . this can also [MASK] threatened by extreme storms . coral ##s are sensitive [MASK] how salty the water is . coral and zoo [MASK] ##nt ##hell ##ae algae both benefit from each other . [MASK] environmental [MASK] ##ors can threaten this bond . environmental stress ##ors can badly affect [MASK] \" balanced philipp \" between coral and zoo [MASK] ##nt ##hell ##ae . there was [MASK] massive coral b ##lea ##ching event in 1998 , it resulted in the [MASK] of 16 % of the world ' s [MASK] reefs . [SEP] these are all different reasons why the rate [MASK] coral b ##lea ##ching goes up [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 101 7760 6038 25078 22216 7591 103 2367 2300 3431 1012 2023 2064 2036 103 5561 2011 6034 12642 1012 11034 2015 2024 7591 103 2129 23592 1996 2300 2003 1012 11034 1998 9201 103 3372 18223 6679 18670 2119 5770 2013 2169 2060 1012 103 4483 103 5668 2064 15686 2023 5416 1012 4483 6911 5668 2064 6649 7461 103 1000 12042 20765 1000 2090 11034 1998 9201 103 3372 18223 6679 1012 2045 2001 103 5294 11034 1038 19738 8450 2724 1999 2687 1010 2009 4504 1999 1996 103 1997 2385 1003 1997 1996 2088 1005 1055 103 21484 1012 102 2122 2024 2035 2367 4436 2339 1996 3446 103 11034 1038 19738 8450 3632 2039 103 102 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.321326 140652228425600 create_pretraining_data.py:161] input_ids: 101 7760 6038 25078 22216 7591 103 2367 2300 3431 1012 2023 2064 2036 103 5561 2011 6034 12642 1012 11034 2015 2024 7591 103 2129 23592 1996 2300 2003 1012 11034 1998 9201 103 3372 18223 6679 18670 2119 5770 2013 2169 2060 1012 103 4483 103 5668 2064 15686 2023 5416 1012 4483 6911 5668 2064 6649 7461 103 1000 12042 20765 1000 2090 11034 1998 9201 103 3372 18223 6679 1012 2045 2001 103 5294 11034 1038 19738 8450 2724 1999 2687 1010 2009 4504 1999 1996 103 1997 2385 1003 1997 1996 2088 1005 1055 103 21484 1012 102 2122 2024 2035 2367 4436 2339 1996 3446 103 11034 1038 19738 8450 3632 2039 103 102 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.321459 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.321597 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 4 6 11 14 24 34 45 47 60 63 69 76 77 90 99 111 116 118 0 0\n",
            "I1030 13:39:40.321722 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 4 6 11 14 24 34 45 47 60 63 69 76 77 90 99 111 116 118 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 2003 2000 2023 2022 2000 18684 3056 6911 1996 3276 18684 1037 5294 2331 11034 1997 3632 1012 0 0\n",
            "I1030 13:39:40.321795 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 2003 2000 2023 2022 2000 18684 3056 6911 1996 3276 18684 1037 5294 2331 11034 1997 3632 1012 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0\n",
            "I1030 13:39:40.321855 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1030 13:39:40.321903 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.322206 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] the year with the most amount of [MASK] ##ora ##l b ##lea [MASK] ##s [MASK] 1998 [MASK] 73 countries reported that they had [MASK] ##ora [MASK] b ##le ##cchi ##ng ##s [MASK] their ocean that year . coral is made up of tiny [MASK] called poly ##ps [MASK] a coral poly ##p has sac [MASK] body and a mouth surrounded by sting ##y tentacles . coral reefs are only found in clear [MASK] shallow , tropical waters . [MASK] [MASK] partly because algae , called zoo ##xa ##nt ##hell ##ae , live in the coral [MASK] and [MASK] light for the process of [MASK] ##yn ##thesis . [SEP] coral ##s are invertebrates [MASK] that live together in colonies and usually stay together in one place . [SEP]\n",
            "I1030 13:39:40.322318 140652228425600 create_pretraining_data.py:151] tokens: [CLS] the year with the most amount of [MASK] ##ora ##l b ##lea [MASK] ##s [MASK] 1998 [MASK] 73 countries reported that they had [MASK] ##ora [MASK] b ##le ##cchi ##ng ##s [MASK] their ocean that year . coral is made up of tiny [MASK] called poly ##ps [MASK] a coral poly ##p has sac [MASK] body and a mouth surrounded by sting ##y tentacles . coral reefs are only found in clear [MASK] shallow , tropical waters . [MASK] [MASK] partly because algae , called zoo ##xa ##nt ##hell ##ae , live in the coral [MASK] and [MASK] light for the process of [MASK] ##yn ##thesis . [SEP] coral ##s are invertebrates [MASK] that live together in colonies and usually stay together in one place . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1996 2095 2007 1996 2087 3815 1997 103 6525 2140 1038 19738 103 2015 103 2687 103 6421 3032 2988 2008 2027 2018 103 6525 103 1038 2571 25955 3070 2015 103 2037 4153 2008 2095 1012 11034 2003 2081 2039 1997 4714 103 2170 26572 4523 103 1037 11034 26572 2361 2038 17266 103 2303 1998 1037 2677 5129 2011 12072 2100 24719 1012 11034 21484 2024 2069 2179 1999 3154 103 8467 1010 5133 5380 1012 103 103 6576 2138 18670 1010 2170 9201 18684 3372 18223 6679 1010 2444 1999 1996 11034 103 1998 103 2422 2005 1996 2832 1997 103 6038 25078 1012 102 11034 2015 2024 25700 103 2008 2444 2362 1999 8355 1998 2788 2994 2362 1999 2028 2173 1012 102\n",
            "I1030 13:39:40.322407 140652228425600 create_pretraining_data.py:161] input_ids: 101 1996 2095 2007 1996 2087 3815 1997 103 6525 2140 1038 19738 103 2015 103 2687 103 6421 3032 2988 2008 2027 2018 103 6525 103 1038 2571 25955 3070 2015 103 2037 4153 2008 2095 1012 11034 2003 2081 2039 1997 4714 103 2170 26572 4523 103 1037 11034 26572 2361 2038 17266 103 2303 1998 1037 2677 5129 2011 12072 2100 24719 1012 11034 21484 2024 2069 2179 1999 3154 103 8467 1010 5133 5380 1012 103 103 6576 2138 18670 1010 2170 9201 18684 3372 18223 6679 1010 2444 1999 1996 11034 103 1998 103 2422 2005 1996 2832 1997 103 6038 25078 1012 102 11034 2015 2024 25700 103 2008 2444 2362 1999 8355 1998 2788 2994 2362 1999 2028 2173 1012 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.322487 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.322598 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 8 13 15 17 24 26 32 44 48 55 58 70 73 79 80 96 98 104 113 0\n",
            "I1030 13:39:40.322658 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 8 13 15 17 24 26 32 44 48 55 58 70 73 79 80 96 98 104 113 0\n",
            "INFO:tensorflow:masked_lm_ids: 18856 8450 2001 1012 18856 2140 1999 4176 1012 10359 1037 2179 1010 2023 2003 14095 2342 7760 4176 0\n",
            "I1030 13:39:40.322714 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 18856 8450 2001 1012 18856 2140 1999 4176 1012 10359 1037 2179 1010 2023 2003 14095 2342 7760 4176 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1030 13:39:40.322772 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.322822 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.323095 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ##s [MASK] in the ocean . some coral have been \" b ##lea ##ched \" a plain white . coral b ##lea ##ching is [MASK] phenomenon [MASK] which coral loses [MASK] [MASK] s ##uous . [MASK] ' s been a serious impact an the world [MASK] [MASK] coral reefs . coral b [MASK] ##ching is more noticeable in the pacific ocean . trade winds have a much more important purpose for earth ##ride [MASK] oceans . up ##well ##ing in [MASK] eastern pacific causes surface waters to be colder [SEP] trade winds affect the rates of coral b ##lea [MASK] [MASK] when water temperatures are higher and trade winds [MASK] lower , more [MASK] end up reporting [MASK] they have [MASK] coral b ##lea ##ching . [SEP]\n",
            "I1030 13:39:40.323200 140652228425600 create_pretraining_data.py:151] tokens: [CLS] ##s [MASK] in the ocean . some coral have been \" b ##lea ##ched \" a plain white . coral b ##lea ##ching is [MASK] phenomenon [MASK] which coral loses [MASK] [MASK] s ##uous . [MASK] ' s been a serious impact an the world [MASK] [MASK] coral reefs . coral b [MASK] ##ching is more noticeable in the pacific ocean . trade winds have a much more important purpose for earth ##ride [MASK] oceans . up ##well ##ing in [MASK] eastern pacific causes surface waters to be colder [SEP] trade winds affect the rates of coral b ##lea [MASK] [MASK] when water temperatures are higher and trade winds [MASK] lower , more [MASK] end up reporting [MASK] they have [MASK] coral b ##lea ##ching . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2015 103 1999 1996 4153 1012 2070 11034 2031 2042 1000 1038 19738 7690 1000 1037 5810 2317 1012 11034 1038 19738 8450 2003 103 9575 103 2029 11034 12386 103 103 1055 8918 1012 103 1005 1055 2042 1037 3809 4254 2019 1996 2088 103 103 11034 21484 1012 11034 1038 103 8450 2003 2062 17725 1999 1996 3534 4153 1012 3119 7266 2031 1037 2172 2062 2590 3800 2005 3011 15637 103 17401 1012 2039 4381 2075 1999 103 2789 3534 5320 3302 5380 2000 2022 21399 102 3119 7266 7461 1996 6165 1997 11034 1038 19738 103 103 2043 2300 7715 2024 3020 1998 3119 7266 103 2896 1010 2062 103 2203 2039 7316 103 2027 2031 103 11034 1038 19738 8450 1012 102\n",
            "I1030 13:39:40.323297 140652228425600 create_pretraining_data.py:161] input_ids: 101 2015 103 1999 1996 4153 1012 2070 11034 2031 2042 1000 1038 19738 7690 1000 1037 5810 2317 1012 11034 1038 19738 8450 2003 103 9575 103 2029 11034 12386 103 103 1055 8918 1012 103 1005 1055 2042 1037 3809 4254 2019 1996 2088 103 103 11034 21484 1012 11034 1038 103 8450 2003 2062 17725 1999 1996 3534 4153 1012 3119 7266 2031 1037 2172 2062 2590 3800 2005 3011 15637 103 17401 1012 2039 4381 2075 1999 103 2789 3534 5320 3302 5380 2000 2022 21399 102 3119 7266 7461 1996 6165 1997 11034 1038 19738 103 103 2043 2300 7715 2024 3020 1998 3119 7266 103 2896 1010 2062 103 2203 2039 7316 103 2027 2031 103 11034 1038 19738 8450 1012 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.323385 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.323464 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 25 27 31 32 34 36 46 47 53 73 74 81 100 101 110 114 118 121 0\n",
            "I1030 13:39:40.323519 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 2 25 27 31 32 34 36 46 47 53 73 74 81 100 101 110 114 118 121 0\n",
            "INFO:tensorflow:masked_lm_ids: 2542 1037 1999 2009 1005 3609 2009 1005 1055 19738 1005 1055 1996 8450 1012 2024 3032 2008 9741 0\n",
            "I1030 13:39:40.323589 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 2542 1037 1999 2009 1005 3609 2009 1005 1055 19738 1005 1055 1996 8450 1012 2024 3032 2008 9741 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1030 13:39:40.323647 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.323706 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.323961 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] during [MASK] ##lea ##ching , coral ##s turn [MASK] due to the e ##ject ##ion or [MASK] of the zoo ##xa ##nt ##hell ##ae algae . [SEP] so when there is weaker [MASK] trades , there ' eurovision higher temper ##aur ##es , [MASK] more [MASK] b ##lea ##ching . another reason for the rates of coral b ##lea ##ching go up [MASK] d [MASK] is photos ##yn dangerous . [SEP]\n",
            "I1030 13:39:40.324063 140652228425600 create_pretraining_data.py:151] tokens: [CLS] during [MASK] ##lea ##ching , coral ##s turn [MASK] due to the e ##ject ##ion or [MASK] of the zoo ##xa ##nt ##hell ##ae algae . [SEP] so when there is weaker [MASK] trades , there ' eurovision higher temper ##aur ##es , [MASK] more [MASK] b ##lea ##ching . another reason for the rates of coral b ##lea ##ching go up [MASK] d [MASK] is photos ##yn dangerous . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2076 103 19738 8450 1010 11034 2015 2735 103 2349 2000 1996 1041 20614 3258 2030 103 1997 1996 9201 18684 3372 18223 6679 18670 1012 102 2061 2043 2045 2003 15863 103 14279 1010 2045 1005 12714 3020 12178 21159 2229 1010 103 2062 103 1038 19738 8450 1012 2178 3114 2005 1996 6165 1997 11034 1038 19738 8450 2175 2039 103 1040 103 2003 7760 6038 4795 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.324156 140652228425600 create_pretraining_data.py:161] input_ids: 101 2076 103 19738 8450 1010 11034 2015 2735 103 2349 2000 1996 1041 20614 3258 2030 103 1997 1996 9201 18684 3372 18223 6679 18670 1012 102 2061 2043 2045 2003 15863 103 14279 1010 2045 1005 12714 3020 12178 21159 2229 1010 103 2062 103 1038 19738 8450 1012 2178 3114 2005 1996 6165 1997 11034 1038 19738 8450 2175 2039 103 1040 103 2003 7760 6038 4795 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.324240 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.332932 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 2 9 17 33 38 42 44 46 63 65 69 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.333043 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 2 9 17 33 38 42 44 46 63 65 69 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 1038 2317 2331 3612 1055 2229 1998 11034 2030 7962 25078 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.333136 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 1038 2317 2331 3612 1055 2229 1998 11034 2030 7962 25078 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.333256 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.333374 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.333802 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] so then the cold water comes up on the shore . [SEP] what leads to the differences in rates of coral b ##lea ##ching is [MASK] coral [MASK] [MASK] ##ching in many oceans , especially in [MASK] pacific [MASK] [SEP]\n",
            "I1030 13:39:40.333970 140652228425600 create_pretraining_data.py:151] tokens: [CLS] so then the cold water comes up on the shore . [SEP] what leads to the differences in rates of coral b ##lea ##ching is [MASK] coral [MASK] [MASK] ##ching in many oceans , especially in [MASK] pacific [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2061 2059 1996 3147 2300 3310 2039 2006 1996 5370 1012 102 2054 5260 2000 1996 5966 1999 6165 1997 11034 1038 19738 8450 2003 103 11034 103 103 8450 1999 2116 17401 1010 2926 1999 103 3534 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.334125 140652228425600 create_pretraining_data.py:161] input_ids: 101 2061 2059 1996 3147 2300 3310 2039 2006 1996 5370 1012 102 2054 5260 2000 1996 5966 1999 6165 1997 11034 1038 19738 8450 2003 103 11034 103 103 8450 1999 2116 17401 1010 2926 1999 103 3534 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.334262 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.334419 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 5 26 28 29 37 39 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.334491 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 5 26 28 29 37 39 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 2300 2008 1038 19738 1996 1012 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.334589 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 2300 2008 1038 19738 1996 1012 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.334695 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.334783 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.335123 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] if the co ##2 rate changes , it can harm the balance needed to keep coral ##s healthy . [SEP] algae is lost [MASK] either dead the coral rayon [MASK] its color and the [MASK] ##lea ##ching event forcibly [MASK] vulnerable to disease [MASK] starvation as stated in the article , [MASK] coral and [MASK] ##xa ##nt ##hall ##ae . \" this can be caused by stress from [MASK] fishing & anchors being dropped on them that [MASK] them [MASK] e ##ject [MASK] marquis or [MASK] the algae . in [MASK] , there are many factors [MASK] can increase the rate of coral b ##lea ##ching among coral ##s . i learned that [MASK] ##xa ##nt ##hall ##ae and coral [MASK] one of the most important [SEP]\n",
            "I1030 13:39:40.335308 140652228425600 create_pretraining_data.py:151] tokens: [CLS] if the co ##2 rate changes , it can harm the balance needed to keep coral ##s healthy . [SEP] algae is lost [MASK] either dead the coral rayon [MASK] its color and the [MASK] ##lea ##ching event forcibly [MASK] vulnerable to disease [MASK] starvation as stated in the article , [MASK] coral and [MASK] ##xa ##nt ##hall ##ae . \" this can be caused by stress from [MASK] fishing & anchors being dropped on them that [MASK] them [MASK] e ##ject [MASK] marquis or [MASK] the algae . in [MASK] , there are many factors [MASK] can increase the rate of coral b ##lea ##ching among coral ##s . i learned that [MASK] ##xa ##nt ##hall ##ae and coral [MASK] one of the most important [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2065 1996 2522 2475 3446 3431 1010 2009 2064 7386 1996 5703 2734 2000 2562 11034 2015 7965 1012 102 18670 2003 2439 103 2593 2757 1996 11034 26810 103 2049 3609 1998 1996 103 19738 8450 2724 20951 103 8211 2000 4295 103 22611 2004 3090 1999 1996 3720 1010 103 11034 1998 103 18684 3372 9892 6679 1012 1000 2023 2064 2022 3303 2011 6911 2013 103 5645 1004 24674 2108 3333 2006 2068 2008 103 2068 103 1041 20614 103 13410 2030 103 1996 18670 1012 1999 103 1010 2045 2024 2116 5876 103 2064 3623 1996 3446 1997 11034 1038 19738 8450 2426 11034 2015 1012 1045 4342 2008 103 18684 3372 9892 6679 1998 11034 103 2028 1997 1996 2087 2590 102\n",
            "I1030 13:39:40.335457 140652228425600 create_pretraining_data.py:161] input_ids: 101 2065 1996 2522 2475 3446 3431 1010 2009 2064 7386 1996 5703 2734 2000 2562 11034 2015 7965 1012 102 18670 2003 2439 103 2593 2757 1996 11034 26810 103 2049 3609 1998 1996 103 19738 8450 2724 20951 103 8211 2000 4295 103 22611 2004 3090 1999 1996 3720 1010 103 11034 1998 103 18684 3372 9892 6679 1012 1000 2023 2064 2022 3303 2011 6911 2013 103 5645 1004 24674 2108 3333 2006 2068 2008 103 2068 103 1041 20614 103 13410 2030 103 1996 18670 1012 1999 103 1010 2045 2024 2116 5876 103 2064 3623 1996 3446 1997 11034 1038 19738 8450 2426 11034 2015 1012 1045 4342 2008 103 18684 3372 9892 6679 1998 11034 103 2028 1997 1996 2087 2590 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.335566 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.335650 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 24 29 30 35 39 40 44 52 55 69 78 80 83 84 86 91 97 114 121 0\n",
            "I1030 13:39:40.335710 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 24 29 30 35 39 40 44 52 55 69 78 80 83 84 86 91 97 114 121 0\n",
            "INFO:tensorflow:masked_lm_ids: 2030 2097 4558 1038 3727 11034 1998 1000 9201 8479 2749 2000 1996 18670 3102 7091 2008 9201 2031 0\n",
            "I1030 13:39:40.335765 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 2030 2097 4558 1038 3727 11034 1998 1000 9201 8479 2749 2000 1996 18670 3102 7091 2008 9201 2031 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1030 13:39:40.335822 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.335872 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.336186 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] other destructive practices can result in the b ##lea ##ching of coral ##s as well . b [MASK] fishing [MASK] example can cause [MASK] damage to the coral ##s . physical [MASK] to the coral ##s . another example is tourists who drop [MASK] or walk on reefs can physically damage coral ##s as well and that [MASK] result in coral b ##lea ##ching . the changes that threaten the coral ##s the most [MASK] the ones in the [MASK] . [SEP] barbecue cause increased stress on [MASK] ##s which results in the death or [MASK] ##ject ##ion of the algae which gives the coral [MASK] [MASK] color . [SEP]\n",
            "I1030 13:39:40.336291 140652228425600 create_pretraining_data.py:151] tokens: [CLS] other destructive practices can result in the b ##lea ##ching of coral ##s as well . b [MASK] fishing [MASK] example can cause [MASK] damage to the coral ##s . physical [MASK] to the coral ##s . another example is tourists who drop [MASK] or walk on reefs can physically damage coral ##s as well and that [MASK] result in coral b ##lea ##ching . the changes that threaten the coral ##s the most [MASK] the ones in the [MASK] . [SEP] barbecue cause increased stress on [MASK] ##s which results in the death or [MASK] ##ject ##ion of the algae which gives the coral [MASK] [MASK] color . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2060 15615 6078 2064 2765 1999 1996 1038 19738 8450 1997 11034 2015 2004 2092 1012 1038 103 5645 103 2742 2064 3426 103 4053 2000 1996 11034 2015 1012 3558 103 2000 1996 11034 2015 1012 2178 2742 2003 9045 2040 4530 103 2030 3328 2006 21484 2064 8186 4053 11034 2015 2004 2092 1998 2008 103 2765 1999 11034 1038 19738 8450 1012 1996 3431 2008 15686 1996 11034 2015 1996 2087 103 1996 3924 1999 1996 103 1012 102 26375 3426 3445 6911 2006 103 2015 2029 3463 1999 1996 2331 2030 103 20614 3258 1997 1996 18670 2029 3957 1996 11034 103 103 3609 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.336379 140652228425600 create_pretraining_data.py:161] input_ids: 101 2060 15615 6078 2064 2765 1999 1996 1038 19738 8450 1997 11034 2015 2004 2092 1012 1038 103 5645 103 2742 2064 3426 103 4053 2000 1996 11034 2015 1012 3558 103 2000 1996 11034 2015 1012 2178 2742 2003 9045 2040 4530 103 2030 3328 2006 21484 2064 8186 4053 11034 2015 2004 2092 1998 2008 103 2765 1999 11034 1038 19738 8450 1012 1996 3431 2008 15686 1996 11034 2015 1996 2087 103 1996 3924 1999 1996 103 1012 102 26375 3426 3445 6911 2006 103 2015 2029 3463 1999 1996 2331 2030 103 20614 3258 1997 1996 18670 2029 3957 1996 11034 103 103 3609 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.336458 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.336566 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 7 14 18 19 20 24 32 44 58 75 79 80 83 88 96 106 107 0 0 0\n",
            "I1030 13:39:40.336621 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 7 14 18 19 20 24 32 44 58 75 79 80 83 88 96 106 107 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 1996 2004 27067 5645 2005 3558 4053 24674 2064 2024 1996 4044 2027 11034 1041 2015 2037 0 0 0\n",
            "I1030 13:39:40.336673 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 1996 2004 27067 5645 2005 3558 4053 24674 2064 2024 1996 4044 2027 11034 1041 2015 2037 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.336725 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1030 13:39:40.336772 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.337028 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] shifting trade winds causes cl [MASK] ##l b ##lea ##ching because changes gospel the amount of co ##2 threaten the delicate balance [MASK] to keep coral ##s [MASK] . as water [MASK] increases , the amount of carbon dioxide in water [MASK] . [SEP] without the algae , they look white or b ##lea [MASK] . [SEP]\n",
            "I1030 13:39:40.337108 140652228425600 create_pretraining_data.py:151] tokens: [CLS] shifting trade winds causes cl [MASK] ##l b ##lea ##ching because changes gospel the amount of co ##2 threaten the delicate balance [MASK] to keep coral ##s [MASK] . as water [MASK] increases , the amount of carbon dioxide in water [MASK] . [SEP] without the algae , they look white or b ##lea [MASK] . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 9564 3119 7266 5320 18856 103 2140 1038 19738 8450 2138 3431 8036 1996 3815 1997 2522 2475 15686 1996 10059 5703 103 2000 2562 11034 2015 103 1012 2004 2300 103 7457 1010 1996 3815 1997 6351 14384 1999 2300 103 1012 102 2302 1996 18670 1010 2027 2298 2317 2030 1038 19738 103 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.337191 140652228425600 create_pretraining_data.py:161] input_ids: 101 9564 3119 7266 5320 18856 103 2140 1038 19738 8450 2138 3431 8036 1996 3815 1997 2522 2475 15686 1996 10059 5703 103 2000 2562 11034 2015 103 1012 2004 2300 103 7457 1010 1996 3815 1997 6351 14384 1999 2300 103 1012 102 2302 1996 18670 1010 2027 2298 2317 2030 1038 19738 103 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.337274 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.337348 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 6 13 23 24 28 32 42 43 55 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.337401 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 6 13 23 24 28 32 42 43 55 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 6525 1999 3223 2000 7965 4860 17913 1012 7690 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.337452 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 6525 1999 3223 2000 7965 4860 17913 1012 7690 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.337505 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1030 13:39:40.337563 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.337817 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] as stated in [MASK] article [MASK] what is coral b ##lea ##ching [MASK] saying that [MASK] pacific [MASK] is where coral b ##lea ##ching is [MASK] done . [SEP] another reason that explains [MASK] rate of coral b ##lea ##ching is the zoo ##xa ##nt ##hell ##age which has a sy ##mb [MASK] ##ic relationship [MASK] coral . when the coral happens to be b ##lea ##ched the zoo ##xa ##nt ##hell ##ae gets affected [MASK] makes [MASK] coral die [MASK] ##sie ##t since it is a living thing , based int [MASK] article \" coral and zoo ##xa [MASK] ##hell ##ae . \" [SEP]\n",
            "I1030 13:39:40.337905 140652228425600 create_pretraining_data.py:151] tokens: [CLS] as stated in [MASK] article [MASK] what is coral b ##lea ##ching [MASK] saying that [MASK] pacific [MASK] is where coral b ##lea ##ching is [MASK] done . [SEP] another reason that explains [MASK] rate of coral b ##lea ##ching is the zoo ##xa ##nt ##hell ##age which has a sy ##mb [MASK] ##ic relationship [MASK] coral . when the coral happens to be b ##lea ##ched the zoo ##xa ##nt ##hell ##ae gets affected [MASK] makes [MASK] coral die [MASK] ##sie ##t since it is a living thing , based int [MASK] article \" coral and zoo ##xa [MASK] ##hell ##ae . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2004 3090 1999 103 3720 103 2054 2003 11034 1038 19738 8450 103 3038 2008 103 3534 103 2003 2073 11034 1038 19738 8450 2003 103 2589 1012 102 2178 3114 2008 7607 103 3446 1997 11034 1038 19738 8450 2003 1996 9201 18684 3372 18223 4270 2029 2038 1037 25353 14905 103 2594 3276 103 11034 1012 2043 1996 11034 6433 2000 2022 1038 19738 7690 1996 9201 18684 3372 18223 6679 4152 5360 103 3084 103 11034 3280 103 11741 2102 2144 2009 2003 1037 2542 2518 1010 2241 20014 103 3720 1000 11034 1998 9201 18684 103 18223 6679 1012 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.337989 140652228425600 create_pretraining_data.py:161] input_ids: 101 2004 3090 1999 103 3720 103 2054 2003 11034 1038 19738 8450 103 3038 2008 103 3534 103 2003 2073 11034 1038 19738 8450 2003 103 2589 1012 102 2178 3114 2008 7607 103 3446 1997 11034 1038 19738 8450 2003 1996 9201 18684 3372 18223 4270 2029 2038 1037 25353 14905 103 2594 3276 103 11034 1012 2043 1996 11034 6433 2000 2022 1038 19738 7690 1996 9201 18684 3372 18223 6679 4152 5360 103 3084 103 11034 3280 103 11741 2102 2144 2009 2003 1037 2542 2518 1010 2241 20014 103 3720 1000 11034 1998 9201 18684 103 18223 6679 1012 1000 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.338068 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.338142 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 4 6 13 16 18 26 28 34 43 53 56 76 78 81 93 100 0 0 0 0\n",
            "I1030 13:39:40.435618 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 4 6 13 16 18 26 28 34 43 53 56 76 78 81 93 100 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 1996 1000 1000 1996 4153 2062 1012 1996 9201 25185 2007 1998 1996 19413 5369 3372 0 0 0 0\n",
            "I1030 13:39:40.435755 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 1996 1000 1000 1996 4153 2062 1012 1996 9201 25185 2007 1998 1996 19413 5369 3372 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.435862 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1030 13:39:40.435922 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.436284 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] after coral loses frank [MASK] it becomes b ##lea [MASK] , it becomes vulnerable to disease and starvation . this algae is necessary for the [MASK] to live because it provides the coral [MASK] co ##2 which [SEP] ran out [MASK] time [SEP]\n",
            "I1030 13:39:40.436422 140652228425600 create_pretraining_data.py:151] tokens: [CLS] after coral loses frank [MASK] it becomes b ##lea [MASK] , it becomes vulnerable to disease and starvation . this algae is necessary for the [MASK] to live because it provides the coral [MASK] co ##2 which [SEP] ran out [MASK] time [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2044 11034 12386 3581 103 2009 4150 1038 19738 103 1010 2009 4150 8211 2000 4295 1998 22611 1012 2023 18670 2003 4072 2005 1996 103 2000 2444 2138 2009 3640 1996 11034 103 2522 2475 2029 102 2743 2041 103 2051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.436587 140652228425600 create_pretraining_data.py:161] input_ids: 101 2044 11034 12386 3581 103 2009 4150 1038 19738 103 1010 2009 4150 8211 2000 4295 1998 22611 1012 2023 18670 2003 4072 2005 1996 103 2000 2444 2138 2009 3640 1996 11034 103 2522 2475 2029 102 2743 2041 103 2051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.436717 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.436854 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 4 5 10 26 34 36 41 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.436958 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 4 5 10 26 34 36 41 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 2049 18670 7690 11034 2007 2475 1997 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.437041 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 2049 18670 7690 11034 2007 2475 1997 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.437128 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1030 13:39:40.437219 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.437748 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] coral b ##lea ##ching is severe so we as humans have to take [MASK] care of the coral reefs . [SEP] this [MASK] the effects because they can ' [MASK] live without it , the coral [MASK] ##ps also give it ' s there color . coral [MASK] all ##l that [MASK] [MASK] it will turn white and [MASK] die . wheeling need to be pre ##to ##ction or sun there will be no more and [MASK] [MASK] hay be harder to learn about . that is about the rates and the [MASK] b ##lea ##ching , so be sure eileen help keep [MASK] soft . [SEP]\n",
            "I1030 13:39:40.437878 140652228425600 create_pretraining_data.py:151] tokens: [CLS] coral b ##lea ##ching is severe so we as humans have to take [MASK] care of the coral reefs . [SEP] this [MASK] the effects because they can ' [MASK] live without it , the coral [MASK] ##ps also give it ' s there color . coral [MASK] all ##l that [MASK] [MASK] it will turn white and [MASK] die . wheeling need to be pre ##to ##ction or sun there will be no more and [MASK] [MASK] hay be harder to learn about . that is about the rates and the [MASK] b ##lea ##ching , so be sure eileen help keep [MASK] soft . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 11034 1038 19738 8450 2003 5729 2061 2057 2004 4286 2031 2000 2202 103 2729 1997 1996 11034 21484 1012 102 2023 103 1996 3896 2138 2027 2064 1005 103 2444 2302 2009 1010 1996 11034 103 4523 2036 2507 2009 1005 1055 2045 3609 1012 11034 103 2035 2140 2008 103 103 2009 2097 2735 2317 1998 103 3280 1012 29142 2342 2000 2022 3653 3406 7542 2030 3103 2045 2097 2022 2053 2062 1998 103 103 10974 2022 6211 2000 4553 2055 1012 2008 2003 2055 1996 6165 1998 1996 103 1038 19738 8450 1010 2061 2022 2469 20495 2393 2562 103 3730 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.437974 140652228425600 create_pretraining_data.py:161] input_ids: 101 11034 1038 19738 8450 2003 5729 2061 2057 2004 4286 2031 2000 2202 103 2729 1997 1996 11034 21484 1012 102 2023 103 1996 3896 2138 2027 2064 1005 103 2444 2302 2009 1010 1996 11034 103 4523 2036 2507 2009 1005 1055 2045 3609 1012 11034 103 2035 2140 2008 103 103 2009 2097 2735 2317 1998 103 3280 1012 29142 2342 2000 2022 3653 3406 7542 2030 3103 2045 2097 2022 2053 2062 1998 103 103 10974 2022 6211 2000 4553 2055 1012 2008 2003 2055 1996 6165 1998 1996 103 1038 19738 8450 1010 2061 2022 2469 20495 2393 2562 103 3730 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.438056 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.438131 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 14 23 30 37 48 52 53 59 62 77 78 79 80 93 101 104 0 0 0 0\n",
            "I1030 13:39:40.438185 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 14 23 30 37 48 52 53 59 62 77 78 79 80 93 101 104 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 2204 3065 1056 26572 3791 2518 2030 2823 2027 1996 11034 2097 2022 11034 2000 2068 0 0 0 0\n",
            "I1030 13:39:40.438236 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 2204 3065 1056 26572 3791 2518 2030 2823 2027 1996 11034 2097 2022 11034 2000 2068 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.438293 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.438340 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.438621 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] coral b ##lea ##ching mostly occurs [MASK] the pacific ocean . [MASK] most coral [MASK] ##lea ##ching reports happened within 1998 . trade winds drag warm [MASK] waters westward while cooler [MASK] in the eastern pacific rise to the surface . coral reefs are only found in clear , shallow , tropical waters . [SEP] algae called ##eed ##xa ##nt [MASK] ##ae live in the coral tissues and need the light for the process of photos ##yn ##thesis . if the photos [MASK] ##thesis is not right do [MASK] low sal ##ini ##ty level [MASK] coral [MASK] become b [MASK] ##ched and lose its color due to dead algae [MASK] [SEP]\n",
            "I1030 13:39:40.438722 140652228425600 create_pretraining_data.py:151] tokens: [CLS] coral b ##lea ##ching mostly occurs [MASK] the pacific ocean . [MASK] most coral [MASK] ##lea ##ching reports happened within 1998 . trade winds drag warm [MASK] waters westward while cooler [MASK] in the eastern pacific rise to the surface . coral reefs are only found in clear , shallow , tropical waters . [SEP] algae called ##eed ##xa ##nt [MASK] ##ae live in the coral tissues and need the light for the process of photos ##yn ##thesis . if the photos [MASK] ##thesis is not right do [MASK] low sal ##ini ##ty level [MASK] coral [MASK] become b [MASK] ##ched and lose its color due to dead algae [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 101 11034 1038 19738 8450 3262 5158 103 1996 3534 4153 1012 103 2087 11034 103 19738 8450 4311 3047 2306 2687 1012 3119 7266 8011 4010 103 5380 15165 2096 14976 103 1999 1996 2789 3534 4125 2000 1996 3302 1012 11034 21484 2024 2069 2179 1999 3154 1010 8467 1010 5133 5380 1012 102 18670 2170 13089 18684 3372 103 6679 2444 1999 1996 11034 14095 1998 2342 1996 2422 2005 1996 2832 1997 7760 6038 25078 1012 2065 1996 7760 103 25078 2003 2025 2157 2079 103 2659 16183 5498 3723 2504 103 11034 103 2468 1038 103 7690 1998 4558 2049 3609 2349 2000 2757 18670 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.438812 140652228425600 create_pretraining_data.py:161] input_ids: 101 11034 1038 19738 8450 3262 5158 103 1996 3534 4153 1012 103 2087 11034 103 19738 8450 4311 3047 2306 2687 1012 3119 7266 8011 4010 103 5380 15165 2096 14976 103 1999 1996 2789 3534 4125 2000 1996 3302 1012 11034 21484 2024 2069 2179 1999 3154 1010 8467 1010 5133 5380 1012 102 18670 2170 13089 18684 3372 103 6679 2444 1999 1996 11034 14095 1998 2342 1996 2422 2005 1996 2832 1997 7760 6038 25078 1012 2065 1996 7760 103 25078 2003 2025 2157 2079 103 2659 16183 5498 3723 2504 103 11034 103 2468 1038 103 7690 1998 4558 2049 3609 2349 2000 2757 18670 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.438890 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.438965 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 7 12 15 27 32 54 58 61 72 83 89 95 97 100 108 110 0 0 0\n",
            "I1030 13:39:40.439018 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 1 7 12 15 27 32 54 58 61 72 83 89 95 97 100 108 110 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 11034 1999 1996 1038 3302 5380 1012 9201 18223 2005 6038 2000 1996 2097 19738 2757 1012 0 0 0\n",
            "I1030 13:39:40.439069 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 11034 1999 1996 1038 3302 5380 1012 9201 18223 2005 6038 2000 1996 2097 19738 2757 1012 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.439122 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1030 13:39:40.439170 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.439425 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] coral b ##lea ##ching are where they arroyo living , the direction trade [MASK] are going , water temperature , sunlight , carbon dioxide , and when [MASK] ##xa ##nt ##hell ##ae algae die . coral b ##lea ##ching connects to [MASK] ocean they are living [MASK] of the temperature . the water should not be to cold for they won ' t loose their color . usually the water [MASK] is from 70 - [MASK] [MASK] [MASK] . the trade [MASK] also take a role on the coral b ##lea ##ching is because it causes the [MASK] [SEP] [MASK] of these stress ##or is when en ##vio [MASK] ##ental forces are so strong that the coral ##s [MASK] ##ject [MASK] food [MASK] producing involved . [SEP]\n",
            "I1030 13:39:40.439538 140652228425600 create_pretraining_data.py:151] tokens: [CLS] coral b ##lea ##ching are where they arroyo living , the direction trade [MASK] are going , water temperature , sunlight , carbon dioxide , and when [MASK] ##xa ##nt ##hell ##ae algae die . coral b ##lea ##ching connects to [MASK] ocean they are living [MASK] of the temperature . the water should not be to cold for they won ' t loose their color . usually the water [MASK] is from 70 - [MASK] [MASK] [MASK] . the trade [MASK] also take a role on the coral b ##lea ##ching is because it causes the [MASK] [SEP] [MASK] of these stress ##or is when en ##vio [MASK] ##ental forces are so strong that the coral ##s [MASK] ##ject [MASK] food [MASK] producing involved . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 11034 1038 19738 8450 2024 2073 2027 23882 2542 1010 1996 3257 3119 103 2024 2183 1010 2300 4860 1010 9325 1010 6351 14384 1010 1998 2043 103 18684 3372 18223 6679 18670 3280 1012 11034 1038 19738 8450 8539 2000 103 4153 2027 2024 2542 103 1997 1996 4860 1012 1996 2300 2323 2025 2022 2000 3147 2005 2027 2180 1005 1056 6065 2037 3609 1012 2788 1996 2300 103 2003 2013 3963 1011 103 103 103 1012 1996 3119 103 2036 2202 1037 2535 2006 1996 11034 1038 19738 8450 2003 2138 2009 5320 1996 103 102 103 1997 2122 6911 2953 2003 2043 4372 25500 103 21050 2749 2024 2061 2844 2008 1996 11034 2015 103 20614 103 2833 103 5155 2920 1012 102\n",
            "I1030 13:39:40.439639 140652228425600 create_pretraining_data.py:161] input_ids: 101 11034 1038 19738 8450 2024 2073 2027 23882 2542 1010 1996 3257 3119 103 2024 2183 1010 2300 4860 1010 9325 1010 6351 14384 1010 1998 2043 103 18684 3372 18223 6679 18670 3280 1012 11034 1038 19738 8450 8539 2000 103 4153 2027 2024 2542 103 1997 1996 4860 1012 1996 2300 2323 2025 2022 2000 3147 2005 2027 2180 1005 1056 6065 2037 3609 1012 2788 1996 2300 103 2003 2013 3963 1011 103 103 103 1012 1996 3119 103 2036 2202 1037 2535 2006 1996 11034 1038 19738 8450 2003 2138 2009 5320 1996 103 102 103 1997 2122 6911 2953 2003 2043 4372 25500 103 21050 2749 2024 2061 2844 2008 1996 11034 2015 103 20614 103 2833 103 5155 2920 1012 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.439716 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.439791 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 8 14 28 42 47 55 71 76 77 78 82 98 100 101 109 119 121 123 125 0\n",
            "I1030 13:39:40.439844 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 8 14 28 42 47 55 71 76 77 78 82 98 100 101 109 119 121 123 125 0\n",
            "INFO:tensorflow:masked_lm_ids: 2024 7266 9201 1996 2138 2025 4860 3770 5445 1042 7266 11034 2028 1997 10867 1041 2037 1011 18670 0\n",
            "I1030 13:39:40.439895 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 2024 7266 9201 1996 2138 2025 4860 3770 5445 1042 7266 11034 2028 1997 10867 1041 2037 1011 18670 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1030 13:39:40.439948 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.439994 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.440248 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] this af ##fa ##cts the balanced relationship . [SEP] but one of [MASK] main causes is [MASK] winds . shifting [MASK] or trade winds are altered every couple of years , causing them to be weakened or reversed [MASK] to blow [MASK] west to east instead troll east to west . [MASK] going [MASK] [MASK] opposite direction ; [MASK] causes the central and eastern pacific regions to swell , thus causing sea [MASK] [MASK] rise from mere inches to as much as a [MASK] . this causes a major change in the [MASK] climate which makes [MASK] ##s en ##vir ##ome ##nt change , forcing [MASK] to change white ( b [MASK] ##ching ) [MASK] [SEP]\n",
            "I1030 13:39:40.440345 140652228425600 create_pretraining_data.py:151] tokens: [CLS] this af ##fa ##cts the balanced relationship . [SEP] but one of [MASK] main causes is [MASK] winds . shifting [MASK] or trade winds are altered every couple of years , causing them to be weakened or reversed [MASK] to blow [MASK] west to east instead troll east to west . [MASK] going [MASK] [MASK] opposite direction ; [MASK] causes the central and eastern pacific regions to swell , thus causing sea [MASK] [MASK] rise from mere inches to as much as a [MASK] . this causes a major change in the [MASK] climate which makes [MASK] ##s en ##vir ##ome ##nt change , forcing [MASK] to change white ( b [MASK] ##ching ) [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2023 21358 7011 16649 1996 12042 3276 1012 102 2021 2028 1997 103 2364 5320 2003 103 7266 1012 9564 103 2030 3119 7266 2024 8776 2296 3232 1997 2086 1010 4786 2068 2000 2022 11855 2030 11674 103 2000 6271 103 2225 2000 2264 2612 18792 2264 2000 2225 1012 103 2183 103 103 4500 3257 1025 103 5320 1996 2430 1998 2789 3534 4655 2000 18370 1010 2947 4786 2712 103 103 4125 2013 8210 5282 2000 2004 2172 2004 1037 103 1012 2023 5320 1037 2350 2689 1999 1996 103 4785 2029 3084 103 2015 4372 21663 8462 3372 2689 1010 6932 103 2000 2689 2317 1006 1038 103 8450 1007 103 102 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.440429 140652228425600 create_pretraining_data.py:161] input_ids: 101 2023 21358 7011 16649 1996 12042 3276 1012 102 2021 2028 1997 103 2364 5320 2003 103 7266 1012 9564 103 2030 3119 7266 2024 8776 2296 3232 1997 2086 1010 4786 2068 2000 2022 11855 2030 11674 103 2000 6271 103 2225 2000 2264 2612 18792 2264 2000 2225 1012 103 2183 103 103 4500 3257 1025 103 5320 1996 2430 1998 2789 3534 4655 2000 18370 1010 2947 4786 2712 103 103 4125 2013 8210 5282 2000 2004 2172 2004 1037 103 1012 2023 5320 1037 2350 2689 1999 1996 103 4785 2029 3084 103 2015 4372 21663 8462 3372 2689 1010 6932 103 2000 2689 2317 1006 1038 103 8450 1007 103 102 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.537972 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.538211 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 13 17 21 39 42 47 52 54 55 59 73 74 84 93 97 106 112 115 0 0\n",
            "I1030 13:39:40.538364 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 13 17 21 39 42 47 52 54 55 59 73 74 84 93 97 106 112 115 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 1996 9564 7266 3294 2013 1997 2011 1999 1996 2009 3798 2000 3329 8484 11034 2009 19738 1012 0 0\n",
            "I1030 13:39:40.538458 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 1996 9564 7266 3294 2013 1997 2011 1999 1996 2009 3798 2000 3329 8484 11034 2009 19738 1012 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0\n",
            "I1030 13:39:40.538537 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.538631 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.539041 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] byu the photos [MASK] ##thesis is not right do to low sal ##ini ##ty level the coral will become 1723 [MASK] [MASK] and lose its color due to dead algae . [SEP] usually , the higher the temperature , the [MASK] [MASK] b [MASK] ##ching there are . so when there is [MASK] wind trades , there ' [MASK] higher temper ##aur ##es , and more coral b ##lea ##ching . another reason for the rates of coral b ##lea ##ching go up or d ##wn is photos [MASK] ##thesis greyish [SEP]\n",
            "I1030 13:39:40.539187 140652228425600 create_pretraining_data.py:151] tokens: [CLS] byu the photos [MASK] ##thesis is not right do to low sal ##ini ##ty level the coral will become 1723 [MASK] [MASK] and lose its color due to dead algae . [SEP] usually , the higher the temperature , the [MASK] [MASK] b [MASK] ##ching there are . so when there is [MASK] wind trades , there ' [MASK] higher temper ##aur ##es , and more coral b ##lea ##ching . another reason for the rates of coral b ##lea ##ching go up or d ##wn is photos [MASK] ##thesis greyish [SEP]\n",
            "INFO:tensorflow:input_ids: 101 23471 1996 7760 103 25078 2003 2025 2157 2079 2000 2659 16183 5498 3723 2504 1996 11034 2097 2468 26621 103 103 1998 4558 2049 3609 2349 2000 2757 18670 1012 102 2788 1010 1996 3020 1996 4860 1010 1996 103 103 1038 103 8450 2045 2024 1012 2061 2043 2045 2003 103 3612 14279 1010 2045 1005 103 3020 12178 21159 2229 1010 1998 2062 11034 1038 19738 8450 1012 2178 3114 2005 1996 6165 1997 11034 1038 19738 8450 2175 2039 2030 1040 7962 2003 7760 103 25078 26916 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.539356 140652228425600 create_pretraining_data.py:161] input_ids: 101 23471 1996 7760 103 25078 2003 2025 2157 2079 2000 2659 16183 5498 3723 2504 1996 11034 2097 2468 26621 103 103 1998 4558 2049 3609 2349 2000 2757 18670 1012 102 2788 1010 1996 3020 1996 4860 1010 1996 103 103 1038 103 8450 2045 2024 1012 2061 2043 2045 2003 103 3612 14279 1010 2045 1005 103 3020 12178 21159 2229 1010 1998 2062 11034 1038 19738 8450 1012 2178 3114 2005 1996 6165 1997 11034 1038 19738 8450 2175 2039 2030 1040 7962 2003 7760 103 25078 26916 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.539495 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.539634 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 4 14 20 21 22 41 42 44 53 59 77 89 91 0 0 0 0 0 0\n",
            "I1030 13:39:40.539723 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 1 4 14 20 21 22 41 42 44 53 59 77 89 91 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 2065 6038 3723 1038 19738 7690 2062 11034 19738 15863 1055 1997 6038 1012 0 0 0 0 0 0\n",
            "I1030 13:39:40.539804 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 2065 6038 3723 1038 19738 7690 2062 11034 19738 15863 1055 1997 6038 1012 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.539885 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.539956 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.540344 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] if coral ##s sustain damage from human activities or environmental forces [MASK] will e ##ject their food producing [MASK] . coral ##s [MASK] white due to e ##ject ##ion or death [MASK] the [MASK] ##xa ##nt [MASK] ##ae algae . [MASK] results leave coral ##s to disease or starvation . [SEP] [MASK] warm ##nes ##t of the water is required to keep [MASK] ##s healthy [MASK] if the water increases over 85 degrees f [MASK] the coral ##s are in a lot of danger . keeping coral ##s safe [MASK] healthy helps [MASK] environment . [SEP]\n",
            "I1030 13:39:40.540485 140652228425600 create_pretraining_data.py:151] tokens: [CLS] if coral ##s sustain damage from human activities or environmental forces [MASK] will e ##ject their food producing [MASK] . coral ##s [MASK] white due to e ##ject ##ion or death [MASK] the [MASK] ##xa ##nt [MASK] ##ae algae . [MASK] results leave coral ##s to disease or starvation . [SEP] [MASK] warm ##nes ##t of the water is required to keep [MASK] ##s healthy [MASK] if the water increases over 85 degrees f [MASK] the coral ##s are in a lot of danger . keeping coral ##s safe [MASK] healthy helps [MASK] environment . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2065 11034 2015 15770 4053 2013 2529 3450 2030 4483 2749 103 2097 1041 20614 2037 2833 5155 103 1012 11034 2015 103 2317 2349 2000 1041 20614 3258 2030 2331 103 1996 103 18684 3372 103 6679 18670 1012 103 3463 2681 11034 2015 2000 4295 2030 22611 1012 102 103 4010 5267 2102 1997 1996 2300 2003 3223 2000 2562 103 2015 7965 103 2065 1996 2300 7457 2058 5594 5445 1042 103 1996 11034 2015 2024 1999 1037 2843 1997 5473 1012 4363 11034 2015 3647 103 7965 7126 103 4044 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.542528 140652228425600 create_pretraining_data.py:161] input_ids: 101 2065 11034 2015 15770 4053 2013 2529 3450 2030 4483 2749 103 2097 1041 20614 2037 2833 5155 103 1012 11034 2015 103 2317 2349 2000 1041 20614 3258 2030 2331 103 1996 103 18684 3372 103 6679 18670 1012 103 3463 2681 11034 2015 2000 4295 2030 22611 1012 102 103 4010 5267 2102 1997 1996 2300 2003 3223 2000 2562 103 2015 7965 103 2065 1996 2300 7457 2058 5594 5445 1042 103 1996 11034 2015 2024 1999 1037 2843 1997 5473 1012 4363 11034 2015 3647 103 7965 7126 103 4044 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.542695 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.542817 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 12 19 23 29 32 34 37 41 52 63 66 75 90 93 0 0 0 0 0\n",
            "I1030 13:39:40.542901 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 1 12 19 23 29 32 34 37 41 52 63 66 75 90 93 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 2065 2009 18670 2735 3258 1997 9201 18223 1996 1996 11034 1012 2059 1998 2256 0 0 0 0 0\n",
            "I1030 13:39:40.542977 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 2065 2009 18670 2735 3258 1997 9201 18223 1996 1996 11034 1012 2059 1998 2256 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.543056 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.543123 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.543514 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] coral b ##lea [MASK] is a phenomenon in which coral loses its color . [SEP] ##lea ##ching ? there [MASK] many [MASK] that cause [MASK] phenomenon , such as up ##well ##ing . up ##well ##ing is [MASK] [MASK] drag warm surface waters west ##ard . up bra ##ing [MASK] [MASK] eastern pacific ocean causes [MASK] [unused86] to be colder than those in the western pacific ocean . this causes the [MASK] to lose its color , [MASK] it needs to be a certain temperature for the coral to be healthy . the most dangerous threats to [MASK] health of [MASK] ##s are [MASK] by changes in their environment when this happens [MASK] the coral e ##ject [MASK] their food - producing algae , causing the [SEP]\n",
            "I1030 13:39:40.543671 140652228425600 create_pretraining_data.py:151] tokens: [CLS] coral b ##lea [MASK] is a phenomenon in which coral loses its color . [SEP] ##lea ##ching ? there [MASK] many [MASK] that cause [MASK] phenomenon , such as up ##well ##ing . up ##well ##ing is [MASK] [MASK] drag warm surface waters west ##ard . up bra ##ing [MASK] [MASK] eastern pacific ocean causes [MASK] [unused86] to be colder than those in the western pacific ocean . this causes the [MASK] to lose its color , [MASK] it needs to be a certain temperature for the coral to be healthy . the most dangerous threats to [MASK] health of [MASK] ##s are [MASK] by changes in their environment when this happens [MASK] the coral e ##ject [MASK] their food - producing algae , causing the [SEP]\n",
            "INFO:tensorflow:input_ids: 101 11034 1038 19738 103 2003 1037 9575 1999 2029 11034 12386 2049 3609 1012 102 19738 8450 1029 2045 103 2116 103 2008 3426 103 9575 1010 2107 2004 2039 4381 2075 1012 2039 4381 2075 2003 103 103 8011 4010 3302 5380 2225 4232 1012 2039 11655 2075 103 103 2789 3534 4153 5320 103 87 2000 2022 21399 2084 2216 1999 1996 2530 3534 4153 1012 2023 5320 1996 103 2000 4558 2049 3609 1010 103 2009 3791 2000 2022 1037 3056 4860 2005 1996 11034 2000 2022 7965 1012 1996 2087 4795 8767 2000 103 2740 1997 103 2015 2024 103 2011 3431 1999 2037 4044 2043 2023 6433 103 1996 11034 1041 20614 103 2037 2833 1011 5155 18670 1010 4786 1996 102\n",
            "I1030 13:39:40.543807 140652228425600 create_pretraining_data.py:161] input_ids: 101 11034 1038 19738 103 2003 1037 9575 1999 2029 11034 12386 2049 3609 1012 102 19738 8450 1029 2045 103 2116 103 2008 3426 103 9575 1010 2107 2004 2039 4381 2075 1012 2039 4381 2075 2003 103 103 8011 4010 3302 5380 2225 4232 1012 2039 11655 2075 103 103 2789 3534 4153 5320 103 87 2000 2022 21399 2084 2216 1999 1996 2530 3534 4153 1012 2023 5320 1996 103 2000 4558 2049 3609 1010 103 2009 3791 2000 2022 1037 3056 4860 2005 1996 11034 2000 2022 7965 1012 1996 2087 4795 8767 2000 103 2740 1997 103 2015 2024 103 2011 3431 1999 2037 4044 2043 2023 6433 103 1996 11034 1041 20614 103 2037 2833 1011 5155 18670 1010 4786 1996 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.543929 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.544042 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 4 20 22 25 28 38 39 48 50 51 56 57 72 78 98 101 104 113 118 0\n",
            "I1030 13:39:40.544119 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 4 20 22 25 28 38 39 48 50 51 56 57 72 78 98 101 104 113 118 0\n",
            "INFO:tensorflow:masked_lm_ids: 8450 2024 2477 2023 2107 2043 7266 4381 1999 1996 3302 5380 11034 2138 1996 11034 3303 1010 2015 0\n",
            "I1030 13:39:40.544192 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 8450 2024 2477 2023 2107 2043 7266 4381 1999 1996 3302 5380 11034 2138 1996 11034 3303 1010 2015 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1030 13:39:40.544273 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1030 13:39:40.544347 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.544745 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] coral comprehend ##lea ##ching is a [MASK] in which coral loses its color . according to the article [MASK] events leading to coral [MASK] ##lea ##ching are a serious problem with a serious impact on the [MASK] ' s coral reefs . [SEP] it ' [MASK] uneasy for coral to live on [MASK] matrix during 1998 , at that year [MASK] trade winds are weak and water [MASK] were [MASK] , many coral ##s were failed on b ##lea [MASK] . many if them didn [MASK] t survive . therefore , the dramatic change [MASK] the trade winds are weaker temper [MASK] ##urt ##e [MASK] cause death of [MASK] ##s . [SEP]\n",
            "I1030 13:39:40.544881 140652228425600 create_pretraining_data.py:151] tokens: [CLS] coral comprehend ##lea ##ching is a [MASK] in which coral loses its color . according to the article [MASK] events leading to coral [MASK] ##lea ##ching are a serious problem with a serious impact on the [MASK] ' s coral reefs . [SEP] it ' [MASK] uneasy for coral to live on [MASK] matrix during 1998 , at that year [MASK] trade winds are weak and water [MASK] were [MASK] , many coral ##s were failed on b ##lea [MASK] . many if them didn [MASK] t survive . therefore , the dramatic change [MASK] the trade winds are weaker temper [MASK] ##urt ##e [MASK] cause death of [MASK] ##s . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 11034 22346 19738 8450 2003 1037 103 1999 2029 11034 12386 2049 3609 1012 2429 2000 1996 3720 103 2824 2877 2000 11034 103 19738 8450 2024 1037 3809 3291 2007 1037 3809 4254 2006 1996 103 1005 1055 11034 21484 1012 102 2009 1005 103 15491 2005 11034 2000 2444 2006 103 8185 2076 2687 1010 2012 2008 2095 103 3119 7266 2024 5410 1998 2300 103 2020 103 1010 2116 11034 2015 2020 3478 2006 1038 19738 103 1012 2116 2065 2068 2134 103 1056 5788 1012 3568 1010 1996 6918 2689 103 1996 3119 7266 2024 15863 12178 103 19585 2063 103 3426 2331 1997 103 2015 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.545013 140652228425600 create_pretraining_data.py:161] input_ids: 101 11034 22346 19738 8450 2003 1037 103 1999 2029 11034 12386 2049 3609 1012 2429 2000 1996 3720 103 2824 2877 2000 11034 103 19738 8450 2024 1037 3809 3291 2007 1037 3809 4254 2006 1996 103 1005 1055 11034 21484 1012 102 2009 1005 103 15491 2005 11034 2000 2444 2006 103 8185 2076 2687 1010 2012 2008 2095 103 3119 7266 2024 5410 1998 2300 103 2020 103 1010 2116 11034 2015 2020 3478 2006 1038 19738 103 1012 2116 2065 2068 2134 103 1056 5788 1012 3568 1010 1996 6918 2689 103 1996 3119 7266 2024 15863 12178 103 19585 2063 103 3426 2331 1997 103 2015 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.545130 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.545243 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 2 7 19 24 37 46 53 54 61 68 70 80 86 95 102 105 109 0 0 0\n",
            "I1030 13:39:40.545328 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 2 7 19 24 37 46 53 54 61 68 70 80 86 95 102 105 109 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 1038 9575 1010 1038 2088 1055 1996 4153 1010 4860 4852 8450 1005 1997 4017 2097 11034 0 0 0\n",
            "I1030 13:39:40.545401 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 1038 9575 1010 1038 2088 1055 1996 4153 1010 4860 4852 8450 1005 1997 4017 2097 11034 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.545484 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.545572 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.545938 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] , [MASK] ##s can sustain physical damage from some destructive practices . in the text it says \" ## water temperature increases , the amount of carbon [MASK] in water decreases \" which [MASK] the [MASK] ##s . i know that because in [MASK] text it says \" reef building coral ##s need [MASK] temperatures between 70 - 85 degrees because the [SEP] [MASK] 1998 the trade winds dropped se ##ver ##ly low and it caused the water te ##mp to rise above coral ##s needed te [MASK] for [MASK] [MASK] [MASK] ( 70 - 85 bentley f [MASK] , and [MASK] the water te ##mp increases the amount of co ##2 decreases , which threatens the delicate balance required to keep coral alive . [SEP]\n",
            "I1030 13:39:40.546061 140652228425600 create_pretraining_data.py:151] tokens: [CLS] [MASK] , [MASK] ##s can sustain physical damage from some destructive practices . in the text it says \" ## water temperature increases , the amount of carbon [MASK] in water decreases \" which [MASK] the [MASK] ##s . i know that because in [MASK] text it says \" reef building coral ##s need [MASK] temperatures between 70 - 85 degrees because the [SEP] [MASK] 1998 the trade winds dropped se ##ver ##ly low and it caused the water te ##mp to rise above coral ##s needed te [MASK] for [MASK] [MASK] [MASK] ( 70 - 85 bentley f [MASK] , and [MASK] the water te ##mp increases the amount of co ##2 decreases , which threatens the delicate balance required to keep coral alive . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 103 1010 103 2015 2064 15770 3558 4053 2013 2070 15615 6078 1012 1999 1996 3793 2009 2758 1000 30157 2300 4860 7457 1010 1996 3815 1997 6351 103 1999 2300 17913 1000 2029 103 1996 103 2015 1012 1045 2113 2008 2138 1999 103 3793 2009 2758 1000 12664 2311 11034 2015 2342 103 7715 2090 3963 1011 5594 5445 2138 1996 102 103 2687 1996 3119 7266 3333 7367 6299 2135 2659 1998 2009 3303 1996 2300 8915 8737 2000 4125 2682 11034 2015 2734 8915 103 2005 103 103 103 1006 3963 1011 5594 15988 1042 103 1010 1998 103 1996 2300 8915 8737 7457 1996 3815 1997 2522 2475 17913 1010 2029 17016 1996 10059 5703 3223 2000 2562 11034 4142 1012 102\n",
            "I1030 13:39:40.546157 140652228425600 create_pretraining_data.py:161] input_ids: 101 103 1010 103 2015 2064 15770 3558 4053 2013 2070 15615 6078 1012 1999 1996 3793 2009 2758 1000 30157 2300 4860 7457 1010 1996 3815 1997 6351 103 1999 2300 17913 1000 2029 103 1996 103 2015 1012 1045 2113 2008 2138 1999 103 3793 2009 2758 1000 12664 2311 11034 2015 2342 103 7715 2090 3963 1011 5594 5445 2138 1996 102 103 2687 1996 3119 7266 3333 7367 6299 2135 2659 1998 2009 3303 1996 2300 8915 8737 2000 4125 2682 11034 2015 2734 8915 103 2005 103 103 103 1006 3963 1011 5594 15988 1042 103 1010 1998 103 1996 2300 8915 8737 7457 1996 3815 1997 2522 2475 17913 1010 2029 17016 1996 10059 5703 3223 2000 2562 11034 4142 1012 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.546240 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1030 13:39:40.642641 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 3 8 20 29 35 37 45 55 65 86 89 91 92 93 96 98 100 103 0\n",
            "I1030 13:39:40.642850 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 1 3 8 20 29 35 37 45 55 65 86 89 91 92 93 96 98 100 103 0\n",
            "INFO:tensorflow:masked_lm_ids: 7965 11034 4053 2004 14384 7386 11034 1996 2300 1999 2015 8737 7760 6038 25078 1011 5445 1007 2004 0\n",
            "I1030 13:39:40.642936 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 7965 11034 4053 2004 14384 7386 11034 1996 2300 1999 2015 8737 7760 6038 25078 1011 5445 1007 2004 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1030 13:39:40.643017 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.643107 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1030 13:39:40.643571 140652228425600 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] things that can lead to [MASK] in the rates of coral b ##lea ##ching could be en ##vio ##rn ##mental stress ##ors that can kill [MASK] zoo ##xa ##nt [MASK] ##ae algae which makes the coral ##s turn white . the co ##2 level [MASK] the [MASK] [MASK] lead to differences in the rates of coral b ##lea ##ching . [SEP] the rates per year are different because of the di ##ff ##onis they use for example as shown in [MASK] graphs [MASK] [MASK] article decrees [SEP]\n",
            "I1030 13:39:40.643746 140652228425600 create_pretraining_data.py:151] tokens: [CLS] things that can lead to [MASK] in the rates of coral b ##lea ##ching could be en ##vio ##rn ##mental stress ##ors that can kill [MASK] zoo ##xa ##nt [MASK] ##ae algae which makes the coral ##s turn white . the co ##2 level [MASK] the [MASK] [MASK] lead to differences in the rates of coral b ##lea ##ching . [SEP] the rates per year are different because of the di ##ff ##onis they use for example as shown in [MASK] graphs [MASK] [MASK] article decrees [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2477 2008 2064 2599 2000 103 1999 1996 6165 1997 11034 1038 19738 8450 2071 2022 4372 25500 6826 26901 6911 5668 2008 2064 3102 103 9201 18684 3372 103 6679 18670 2029 3084 1996 11034 2015 2735 2317 1012 1996 2522 2475 2504 103 1996 103 103 2599 2000 5966 1999 1996 6165 1997 11034 1038 19738 8450 1012 102 1996 6165 2566 2095 2024 2367 2138 1997 1996 4487 4246 27296 2027 2224 2005 2742 2004 3491 1999 103 19287 103 103 3720 28966 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.643895 140652228425600 create_pretraining_data.py:161] input_ids: 101 2477 2008 2064 2599 2000 103 1999 1996 6165 1997 11034 1038 19738 8450 2071 2022 4372 25500 6826 26901 6911 5668 2008 2064 3102 103 9201 18684 3372 103 6679 18670 2029 3084 1996 11034 2015 2735 2317 1012 1996 2522 2475 2504 103 1996 103 103 2599 2000 5966 1999 1996 6165 1997 11034 1038 19738 8450 1012 102 1996 6165 2566 2095 2024 2367 2138 1997 1996 4487 4246 27296 2027 2224 2005 2742 2004 3491 1999 103 19287 103 103 3720 28966 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.644015 140652228425600 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.644159 140652228425600 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 6 26 29 30 45 47 48 62 73 81 83 84 86 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.644260 140652228425600 create_pretraining_data.py:161] masked_lm_positions: 6 26 29 30 45 47 48 62 73 81 83 84 86 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 5966 1996 3372 18223 1997 11034 2064 1996 2477 1996 1999 1996 1012 0 0 0 0 0 0 0\n",
            "I1030 13:39:40.644346 140652228425600 create_pretraining_data.py:161] masked_lm_ids: 5966 1996 3372 18223 1997 11034 2064 1996 2477 1996 1999 1996 1012 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1030 13:39:40.644447 140652228425600 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1030 13:39:40.644518 140652228425600 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:Wrote 12021 total instances\n",
            "I1030 13:39:42.868217 140652228425600 create_pretraining_data.py:166] Wrote 12021 total instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYC4bvxApriY"
      },
      "source": [
        "OUTPUT_PATH = 'colab/bert/bert_pretraining/coral_bleaching_pretraining_output'\n",
        "CONFIG_PATH = 'colab/bert/bert_base_uncased/bert_config.json'\n",
        "CKPT_PATH = 'colab/bert/bert_base_uncased/bert_model.ckpt.index'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_UOF8ECozAA",
        "outputId": "e3f06b73-84cc-436c-a4d8-5f2afb9ccec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python colab/bert/run_pretraining.py \\\n",
        "  --input_file=$TF_RECORD_PATH \\\n",
        "  --output_dir=$OUTPUT_PATH \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --bert_config_file=$CONFIG_PATH \\\n",
        "  --init_checkpoint=$CKPT_PATH \\\n",
        "  --train_batch_size=$BATCH_SIZE \\\n",
        "  --max_seq_length=$MAX_SEQ_LEN \\\n",
        "  --max_predictions_per_seq=$MAX_PRED_PER_SEQ \\\n",
        "  --num_train_steps=$TRAIN_STEPS \\\n",
        "  --num_warmup_steps=$WARMUP_STEPS \\\n",
        "  --learning_rate=$LEARNING_RATE"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/colab/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W1030 13:39:47.712918 140695103870848 module_wrapper.py:139] From colab/bert/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1030 13:39:47.713079 140695103870848 module_wrapper.py:139] From colab/bert/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/colab/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1030 13:39:47.713202 140695103870848 module_wrapper.py:139] From /content/drive/My Drive/colab/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W1030 13:39:48.394889 140695103870848 module_wrapper.py:139] From colab/bert/run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W1030 13:39:48.395463 140695103870848 module_wrapper.py:139] From colab/bert/run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1030 13:39:48.397002 140695103870848 module_wrapper.py:139] From colab/bert/run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:*** Input Files ***\n",
            "I1030 13:39:48.397136 140695103870848 run_pretraining.py:420] *** Input Files ***\n",
            "INFO:tensorflow:  colab/bert/bert_pretraining/coral_bleaching_pretraining.tfrecord\n",
            "I1030 13:39:48.397206 140695103870848 run_pretraining.py:422]   colab/bert/bert_pretraining/coral_bleaching_pretraining.tfrecord\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W1030 13:39:48.397327 140695103870848 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "I1030 13:39:49.295581 140695103870848 utils.py:141] NumExpr defaulting to 4 threads.\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7ff5b7b9bae8>) includes params argument, but params are not passed to Estimator.\n",
            "W1030 13:39:50.389073 140695103870848 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7ff5b7b9bae8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'colab/bert/bert_pretraining/coral_bleaching_pretraining_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff5b7b4aef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "I1030 13:39:50.390353 140695103870848 estimator.py:212] Using config: {'_model_dir': 'colab/bert/bert_pretraining/coral_bleaching_pretraining_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff5b7b4aef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I1030 13:39:50.390683 140695103870848 tpu_context.py:220] _TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "W1030 13:39:50.391302 140695103870848 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n",
            "INFO:tensorflow:***** Running training *****\n",
            "I1030 13:39:50.391415 140695103870848 run_pretraining.py:459] ***** Running training *****\n",
            "INFO:tensorflow:  Batch size = 32\n",
            "I1030 13:39:50.391482 140695103870848 run_pretraining.py:460]   Batch size = 32\n",
            "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
            "I1030 13:39:53.038287 140695103870848 estimator.py:363] Skipping training since max_steps has already saved.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "I1030 13:39:53.038506 140695103870848 error_handling.py:101] training_loop marked as finished\n",
            "INFO:tensorflow:***** Running evaluation *****\n",
            "I1030 13:39:53.038663 140695103870848 run_pretraining.py:469] ***** Running evaluation *****\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I1030 13:39:53.038763 140695103870848 run_pretraining.py:470]   Batch size = 8\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W1030 13:39:53.049229 140695103870848 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W1030 13:39:53.050057 140695103870848 module_wrapper.py:139] From colab/bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W1030 13:39:53.067270 140695103870848 deprecation.py:323] From colab/bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W1030 13:39:53.067445 140695103870848 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:Entity <function input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7ff5b680f0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W1030 13:39:53.080684 140695103870848 ag_logging.py:146] Entity <function input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7ff5b680f0d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W1030 13:39:53.080878 140695103870848 module_wrapper.py:139] From colab/bert/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1030 13:39:53.092526 140695103870848 deprecation.py:323] From colab/bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1030 13:39:53.114796 140695103870848 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Running eval on CPU\n",
            "I1030 13:39:53.114974 140695103870848 tpu_estimator.py:3124] Running eval on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I1030 13:39:53.115248 140695103870848 run_pretraining.py:117] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (8, 128)\n",
            "I1030 13:39:53.115357 140695103870848 run_pretraining.py:119]   name = input_ids, shape = (8, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (8, 128)\n",
            "I1030 13:39:53.115432 140695103870848 run_pretraining.py:119]   name = input_mask, shape = (8, 128)\n",
            "INFO:tensorflow:  name = masked_lm_ids, shape = (8, 20)\n",
            "I1030 13:39:53.115506 140695103870848 run_pretraining.py:119]   name = masked_lm_ids, shape = (8, 20)\n",
            "INFO:tensorflow:  name = masked_lm_positions, shape = (8, 20)\n",
            "I1030 13:39:53.115583 140695103870848 run_pretraining.py:119]   name = masked_lm_positions, shape = (8, 20)\n",
            "INFO:tensorflow:  name = masked_lm_weights, shape = (8, 20)\n",
            "I1030 13:39:53.115681 140695103870848 run_pretraining.py:119]   name = masked_lm_weights, shape = (8, 20)\n",
            "INFO:tensorflow:  name = next_sentence_labels, shape = (8, 1)\n",
            "I1030 13:39:53.115740 140695103870848 run_pretraining.py:119]   name = next_sentence_labels, shape = (8, 1)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (8, 128)\n",
            "I1030 13:39:53.115797 140695103870848 run_pretraining.py:119]   name = segment_ids, shape = (8, 128)\n",
            "WARNING:tensorflow:From /content/drive/My Drive/colab/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W1030 13:39:53.115961 140695103870848 module_wrapper.py:139] From /content/drive/My Drive/colab/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/colab/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W1030 13:39:53.117094 140695103870848 module_wrapper.py:139] From /content/drive/My Drive/colab/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/colab/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W1030 13:39:53.134089 140695103870848 module_wrapper.py:139] From /content/drive/My Drive/colab/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/colab/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W1030 13:39:53.167886 140695103870848 deprecation.py:323] From /content/drive/My Drive/colab/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1030 13:39:53.168991 140695103870848 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W1030 13:39:54.547210 140695103870848 module_wrapper.py:139] From colab/bert/run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:165: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W1030 13:39:55.741409 140695103870848 module_wrapper.py:139] From colab/bert/run_pretraining.py:165: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I1030 13:39:55.745108 140695103870848 run_pretraining.py:167] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768)\n",
            "I1030 13:39:55.745336 140695103870848 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "I1030 13:39:55.745463 140695103870848 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "I1030 13:39:55.745565 140695103870848 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.745667 140695103870848 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.745740 140695103870848 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.745808 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.745877 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.745944 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.746021 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.746087 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.746152 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.746218 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.746284 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.746348 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.746412 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.746505 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.746716 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.746791 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.746859 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.746922 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.746986 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.747058 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.747125 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.747190 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.747256 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.747322 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.747388 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.747453 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.747519 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.747625 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.747695 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.747760 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.747827 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.747893 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.747958 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.748025 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.748087 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.748149 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.748214 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.748276 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.748341 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.748404 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.748468 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.748535 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.748633 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.748702 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.748768 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.748832 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.748897 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.748960 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.749031 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.749094 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.749155 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.749217 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.749283 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.749348 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.749421 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.749485 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.749575 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.749660 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.749728 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.749791 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.749853 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.749915 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.749980 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.750050 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.750115 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.750182 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.750254 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.750319 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.750384 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.750447 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.750512 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.750606 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.750678 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.750743 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.750808 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.750872 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.822851 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.822988 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.823122 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.823254 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.823401 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.823514 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.823606 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.823708 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.823837 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.823951 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.824044 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.824141 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.824261 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.824370 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.824442 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.824540 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.824682 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.824774 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.824848 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.824975 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.825130 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.825205 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.825298 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.825419 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.825519 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.825625 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.825741 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.825870 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.825949 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.826046 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.826168 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.826267 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.826333 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.826428 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.826602 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.826699 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.826784 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.826894 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.827025 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.827102 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.827189 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.827312 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.827423 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.827497 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.827636 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.827741 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.827813 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.827886 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.827986 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.828061 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.828140 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.828256 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.828382 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.828462 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.828567 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.828692 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.828810 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.828885 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.829007 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.829175 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.829274 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.829399 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.829536 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.829662 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.829773 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.829904 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.830039 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.830126 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.830265 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.830396 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.830472 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.830568 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.830704 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.830791 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.830860 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.830948 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.831047 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.831116 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.831217 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.831304 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.831369 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.831468 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.831614 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.831757 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.831879 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.831952 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.832051 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.832170 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.832272 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.832346 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.832461 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.832593 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.832674 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.832763 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.832885 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.832986 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.833060 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.833163 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.833303 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.833384 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.833472 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.833601 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.833713 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.833783 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "I1030 13:39:55.833889 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.834023 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "I1030 13:39:55.834116 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.834208 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "I1030 13:39:55.834311 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.834382 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.834478 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.834611 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.834745 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I1030 13:39:55.834836 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "I1030 13:39:55.834930 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "I1030 13:39:55.835058 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.835174 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.835245 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.835359 140695103870848 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.835484 140695103870848 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.835586 140695103870848 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "I1030 13:39:55.835695 140695103870848 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "I1030 13:39:55.835795 140695103870848 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "I1030 13:39:55.835863 140695103870848 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "I1030 13:39:55.835941 140695103870848 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (30522,)\n",
            "I1030 13:39:55.836061 140695103870848 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (30522,)\n",
            "INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "I1030 13:39:55.836193 140695103870848 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "I1030 13:39:55.836292 140695103870848 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:198: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W1030 13:39:55.841516 140695103870848 module_wrapper.py:139] From colab/bert/run_pretraining.py:198: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "WARNING:tensorflow:From colab/bert/run_pretraining.py:202: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W1030 13:39:55.853907 140695103870848 module_wrapper.py:139] From colab/bert/run_pretraining.py:202: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1030 13:39:55.887891 140695103870848 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-10-30T13:39:55Z\n",
            "I1030 13:39:55.902610 140695103870848 evaluation.py:255] Starting evaluation at 2020-10-30T13:39:55Z\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1030 13:39:56.059499 140695103870848 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1030 13:39:56.328186 140695103870848 monitored_session.py:240] Graph was finalized.\n",
            "2020-10-30 13:39:56.338642: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-10-30 13:39:56.338910: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20ccd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-30 13:39:56.338948: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-30 13:39:56.341210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-30 13:39:56.431312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 13:39:56.432055: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20ccf40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-30 13:39:56.432086: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-10-30 13:39:56.432221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 13:39:56.432750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-30 13:39:56.433020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-30 13:39:56.434391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-30 13:39:56.435842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-30 13:39:56.436150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-30 13:39:56.437532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-30 13:39:56.438255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-30 13:39:56.441320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-30 13:39:56.441416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 13:39:56.441969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 13:39:56.442445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-30 13:39:56.442495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-30 13:39:56.443650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-30 13:39:56.443674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-10-30 13:39:56.443682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-10-30 13:39:56.443776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 13:39:56.444278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-30 13:39:56.444790: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-30 13:39:56.444826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from colab/bert/bert_pretraining/coral_bleaching_pretraining_output/model.ckpt-100000\n",
            "I1030 13:39:56.447881 140695103870848 saver.py:1284] Restoring parameters from colab/bert/bert_pretraining/coral_bleaching_pretraining_output/model.ckpt-100000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1030 13:40:16.301366 140695103870848 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1030 13:40:16.340560 140695103870848 session_manager.py:502] Done running local_init_op.\n",
            "2020-10-30 13:40:16.861270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:Evaluation [10/100]\n",
            "I1030 13:40:19.401225 140695103870848 evaluation.py:167] Evaluation [10/100]\n",
            "INFO:tensorflow:Evaluation [20/100]\n",
            "I1030 13:40:19.888816 140695103870848 evaluation.py:167] Evaluation [20/100]\n",
            "INFO:tensorflow:Evaluation [30/100]\n",
            "I1030 13:40:20.375765 140695103870848 evaluation.py:167] Evaluation [30/100]\n",
            "INFO:tensorflow:Evaluation [40/100]\n",
            "I1030 13:40:20.864059 140695103870848 evaluation.py:167] Evaluation [40/100]\n",
            "INFO:tensorflow:Evaluation [50/100]\n",
            "I1030 13:40:21.350887 140695103870848 evaluation.py:167] Evaluation [50/100]\n",
            "INFO:tensorflow:Evaluation [60/100]\n",
            "I1030 13:40:21.837913 140695103870848 evaluation.py:167] Evaluation [60/100]\n",
            "INFO:tensorflow:Evaluation [70/100]\n",
            "I1030 13:40:22.324296 140695103870848 evaluation.py:167] Evaluation [70/100]\n",
            "INFO:tensorflow:Evaluation [80/100]\n",
            "I1030 13:40:22.811520 140695103870848 evaluation.py:167] Evaluation [80/100]\n",
            "INFO:tensorflow:Evaluation [90/100]\n",
            "I1030 13:40:23.301742 140695103870848 evaluation.py:167] Evaluation [90/100]\n",
            "INFO:tensorflow:Evaluation [100/100]\n",
            "I1030 13:40:23.788999 140695103870848 evaluation.py:167] Evaluation [100/100]\n",
            "INFO:tensorflow:Finished evaluation at 2020-10-30-13:40:23\n",
            "I1030 13:40:23.859945 140695103870848 evaluation.py:275] Finished evaluation at 2020-10-30-13:40:23\n",
            "INFO:tensorflow:Saving dict for global step 100000: global_step = 100000, loss = 0.07374086, masked_lm_accuracy = 0.9909886, masked_lm_loss = 0.07412144, next_sentence_accuracy = 1.0, next_sentence_loss = 7.45058e-10\n",
            "I1030 13:40:23.860189 140695103870848 estimator.py:2049] Saving dict for global step 100000: global_step = 100000, loss = 0.07374086, masked_lm_accuracy = 0.9909886, masked_lm_loss = 0.07412144, next_sentence_accuracy = 1.0, next_sentence_loss = 7.45058e-10\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100000: colab/bert/bert_pretraining/coral_bleaching_pretraining_output/model.ckpt-100000\n",
            "I1030 13:40:24.162160 140695103870848 estimator.py:2109] Saving 'checkpoint_path' summary for global step 100000: colab/bert/bert_pretraining/coral_bleaching_pretraining_output/model.ckpt-100000\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "I1030 13:40:24.163123 140695103870848 error_handling.py:101] evaluation_loop marked as finished\n",
            "INFO:tensorflow:***** Eval results *****\n",
            "I1030 13:40:24.163339 140695103870848 run_pretraining.py:483] ***** Eval results *****\n",
            "INFO:tensorflow:  global_step = 100000\n",
            "I1030 13:40:24.163425 140695103870848 run_pretraining.py:485]   global_step = 100000\n",
            "INFO:tensorflow:  loss = 0.07374086\n",
            "I1030 13:40:24.661874 140695103870848 run_pretraining.py:485]   loss = 0.07374086\n",
            "INFO:tensorflow:  masked_lm_accuracy = 0.9909886\n",
            "I1030 13:40:24.662154 140695103870848 run_pretraining.py:485]   masked_lm_accuracy = 0.9909886\n",
            "INFO:tensorflow:  masked_lm_loss = 0.07412144\n",
            "I1030 13:40:24.662269 140695103870848 run_pretraining.py:485]   masked_lm_loss = 0.07412144\n",
            "INFO:tensorflow:  next_sentence_accuracy = 1.0\n",
            "I1030 13:40:24.662366 140695103870848 run_pretraining.py:485]   next_sentence_accuracy = 1.0\n",
            "INFO:tensorflow:  next_sentence_loss = 7.45058e-10\n",
            "I1030 13:40:24.662459 140695103870848 run_pretraining.py:485]   next_sentence_loss = 7.45058e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgF-9cbpllJj"
      },
      "source": [
        "TOTAL_LOSS = 0.07374086\n",
        "MASKED_LM_ACC = 0.9909886\n",
        "MASKED_LM_LOSS = 0.07412144\n",
        "NSP_ACC = 1.0\n",
        "NSP_LOSS = 7.45058e-10"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-ITOwEDh6gM"
      },
      "source": [
        "# Create the file to store the stats of the pretraining if it doesn't already exist\n",
        "import os\n",
        "\n",
        "STATS_PATH = \"colab/stats/coral_bleaching_pretraining_stats.csv\"\n",
        "\n",
        "f = None\n",
        "if not os.path.isfile(STATS_PATH):\n",
        "  f = open(STATS_PATH, \"w\")\n",
        "  f.write(\"number,datetime,bert_model,pretraining_type,seed,max_seq_len,masked_lm_prob,\\\n",
        "          dupe_factor,max_pred_per_seq,batch_size,train_steps,warmup_steps,learning_rate,\\\n",
        "          masked_lm_acc,masked_lm_loss,nsp_acc,nsp_loss,total_loss,notes\\n\")\n",
        "  print(\"coral_bleaching_stats.csv NOT found - creating\")\n",
        "  f.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxwsWSudjOlH"
      },
      "source": [
        "def getLastModelNumber():\n",
        "  try:\n",
        "    with open(STATS_PATH, \"r\") as f:\n",
        "      f_list = list(f)\n",
        "      latest = f_list[-1].split(',')\n",
        "      return int(latest[0])\n",
        "  except:\n",
        "    return -1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "denOE0ApjUlS",
        "outputId": "2dcc5c98-62e4-459c-e13d-09cb3a889761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# We will use this in the future to refer to the current model\n",
        "num = str(getLastModelNumber() + 1)\n",
        "num"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'9'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlLPky2vilLv",
        "outputId": "b85986f5-cc41-4d43-9e18-f02c7016e684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Get date and time\n",
        "import datetime\n",
        "import pytz\n",
        "\n",
        "date = str(datetime.datetime.now(tz = pytz.timezone('US/Central')))\n",
        "date = date.split(' ')\n",
        "time = date[1]\n",
        "date = date[0]\n",
        "h, m = [time.split(':')[0], time.split(':')[1]]\n",
        "\n",
        "DATE_TIME = date + ' ' + h + ':' + m + \" CT\"\n",
        "DATE_TIME"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-10-30 08:40 CT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99dOqt8Zi8jp"
      },
      "source": [
        "# Add line to params, then save and close\n",
        "with open(STATS_PATH, \"a\") as f:\n",
        "  f.write(\"{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},\\\n",
        "          {12},{13},{14},{15},{16},{17},{18}\\n\".format(num,DATE_TIME,BERT_MODEL,PRETRAINING_TYPE,SEED,\n",
        "                                                  MAX_SEQ_LEN,MASKED_LM_PROB,DUPE_FACTOR,MAX_PRED_PER_SEQ,\n",
        "                                                  BATCH_SIZE,TRAIN_STEPS,WARMUP_STEPS,LEARNING_RATE,\n",
        "                                                  MASKED_LM_ACC,MASKED_LM_LOSS,NSP_ACC,NSP_LOSS,TOTAL_LOSS,NOTES))"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}